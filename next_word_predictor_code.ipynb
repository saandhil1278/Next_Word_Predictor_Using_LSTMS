{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf1aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs=\"\"\"Saandhil Agarwal\n",
    " Bachelor of Technology\n",
    " Information Technology\n",
    " Birla Institute of Technology, Mesra\n",
    " \n",
    "Education\n",
    " Birla Institute of Technology, Mesra\n",
    " B.Tech in Information Technology\n",
    " New Look Uchtar Madhyamik Vidyalaya, Kota\n",
    " Central Board of Secondary Education\n",
    " \n",
    "Experience\n",
    " YHills\n",
    " Campus Ambassador\n",
    " Organized and managed with a group of students for the smooth enrollment of students in courses\n",
    " Addressed queries,implemented innovative strategies and increased student engagement significantly\n",
    " \n",
    "Personal Projects\n",
    " AI Powered Movie Recommender System (Machine Learning)\n",
    " Applied comprehensive feature engineering techniques including feature transformation, feature extraction and One Hot\n",
    " Encoding along with pandas profiling for thorough data analysis. Utilized text vectorization, cosine similarities and\n",
    " integrated APIs with streamlit’s interactive widgets with effortless deployment for movie recommendation\n",
    "Beverage Vista- A sales dashboard of refreshment drinks (Power BI)\n",
    " Leveraged Power BI for detailed analytics in American beverage sales along with dynamic charts using filters & slices.\n",
    " Explored trends across states and cities and implemented tool tips for insights contributing to strategic decision-making\n",
    " Next Word Predictor using LSTM and LLMs (Deep Learning, NLP)\n",
    " Developed a Natural Language Processing Model using LSTM & LLM techniques for predicting the next word in text se\n",
    "quences using language modelling. Used Keras, PyTorch and TensorFlow frameworks to implement the model incorporating\n",
    " embedding layers, LSTM and Softmax layers to achieve high accuracy through hyper-parameter tuning.\n",
    "\n",
    "\n",
    "Technical Skills and Interests\n",
    " Languages and Libraries: Python, C/C++, Numpy, Pandas, Matplotlib, Scikit-learn, Seaborn, Streamlit, SQL\n",
    " Developer Tools: Git/GitHub, Pycharm, Power BI, Jupyter Notebook, Google Colab, VS-Code\n",
    " Frameworks: Keras, TensorFlow, PyTorch\n",
    " Interests: Machine Learning, Deep Learning, NLP, GenAI\n",
    " Coursework:– Image Processing and Pattern Recognition– Natural Language Processing– Data Mining– Operating Systems and Data Base Management Systems\n",
    " \n",
    " Positions of Responsibility\n",
    " Event Organizer, Sports and Adventure Club, BIT Mesra\n",
    " Senior Executive, Dhwani, BIT Mesra\n",
    " \n",
    " Certifications and Achievements\n",
    " Google Analytics Accreditation\n",
    " Showcasing proficiency in data analysis and visualization for informed decision making\n",
    "Udemy’s Machine Learning Course\n",
    " Accomplished a comprehensive \"Machine Learning in 21 days\" course on Udemy applying algorithms on real world datasets\n",
    " Special Mention in Model United Nations\n",
    " Recieved a Special Mention and a Verbal Mention in the UNHRC Committee for 2 consecutive years\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc629a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saandhil agarwal\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1c8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f247737",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([faqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba368e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 1,\n",
       " 'of': 2,\n",
       " 'in': 3,\n",
       " 'for': 4,\n",
       " 'a': 5,\n",
       " 'learning': 6,\n",
       " 'technology': 7,\n",
       " 'with': 8,\n",
       " 'mesra': 9,\n",
       " 'the': 10,\n",
       " 'machine': 11,\n",
       " 'data': 12,\n",
       " 'using': 13,\n",
       " 'feature': 14,\n",
       " 'power': 15,\n",
       " 'bi': 16,\n",
       " 'to': 17,\n",
       " 'lstm': 18,\n",
       " 'language': 19,\n",
       " 'model': 20,\n",
       " 'mention': 21,\n",
       " 'information': 22,\n",
       " 'birla': 23,\n",
       " 'institute': 24,\n",
       " 'education': 25,\n",
       " 'students': 26,\n",
       " 'implemented': 27,\n",
       " 'movie': 28,\n",
       " 'comprehensive': 29,\n",
       " 'techniques': 30,\n",
       " 'along': 31,\n",
       " 'pandas': 32,\n",
       " 'analysis': 33,\n",
       " 'text': 34,\n",
       " 'beverage': 35,\n",
       " 'sales': 36,\n",
       " 'analytics': 37,\n",
       " 'decision': 38,\n",
       " 'making': 39,\n",
       " 'next': 40,\n",
       " 'word': 41,\n",
       " 'deep': 42,\n",
       " 'nlp': 43,\n",
       " 'natural': 44,\n",
       " 'processing': 45,\n",
       " 'keras': 46,\n",
       " 'pytorch': 47,\n",
       " 'tensorflow': 48,\n",
       " 'frameworks': 49,\n",
       " 'layers': 50,\n",
       " 'interests': 51,\n",
       " 'c': 52,\n",
       " 'google': 53,\n",
       " 'systems': 54,\n",
       " 'bit': 55,\n",
       " 'course': 56,\n",
       " 'on': 57,\n",
       " 'special': 58,\n",
       " 'saandhil': 59,\n",
       " 'agarwal': 60,\n",
       " 'bachelor': 61,\n",
       " 'b': 62,\n",
       " 'tech': 63,\n",
       " 'new': 64,\n",
       " 'look': 65,\n",
       " 'uchtar': 66,\n",
       " 'madhyamik': 67,\n",
       " 'vidyalaya': 68,\n",
       " 'kota': 69,\n",
       " 'central': 70,\n",
       " 'board': 71,\n",
       " 'secondary': 72,\n",
       " 'experience': 73,\n",
       " 'yhills': 74,\n",
       " 'campus': 75,\n",
       " 'ambassador': 76,\n",
       " 'organized': 77,\n",
       " 'managed': 78,\n",
       " 'group': 79,\n",
       " 'smooth': 80,\n",
       " 'enrollment': 81,\n",
       " 'courses': 82,\n",
       " 'addressed': 83,\n",
       " 'queries': 84,\n",
       " 'innovative': 85,\n",
       " 'strategies': 86,\n",
       " 'increased': 87,\n",
       " 'student': 88,\n",
       " 'engagement': 89,\n",
       " 'significantly': 90,\n",
       " 'personal': 91,\n",
       " 'projects': 92,\n",
       " 'ai': 93,\n",
       " 'powered': 94,\n",
       " 'recommender': 95,\n",
       " 'system': 96,\n",
       " 'applied': 97,\n",
       " 'engineering': 98,\n",
       " 'including': 99,\n",
       " 'transformation': 100,\n",
       " 'extraction': 101,\n",
       " 'one': 102,\n",
       " 'hot': 103,\n",
       " 'encoding': 104,\n",
       " 'profiling': 105,\n",
       " 'thorough': 106,\n",
       " 'utilized': 107,\n",
       " 'vectorization': 108,\n",
       " 'cosine': 109,\n",
       " 'similarities': 110,\n",
       " 'integrated': 111,\n",
       " 'apis': 112,\n",
       " 'streamlit’s': 113,\n",
       " 'interactive': 114,\n",
       " 'widgets': 115,\n",
       " 'effortless': 116,\n",
       " 'deployment': 117,\n",
       " 'recommendation': 118,\n",
       " 'vista': 119,\n",
       " 'dashboard': 120,\n",
       " 'refreshment': 121,\n",
       " 'drinks': 122,\n",
       " 'leveraged': 123,\n",
       " 'detailed': 124,\n",
       " 'american': 125,\n",
       " 'dynamic': 126,\n",
       " 'charts': 127,\n",
       " 'filters': 128,\n",
       " 'slices': 129,\n",
       " 'explored': 130,\n",
       " 'trends': 131,\n",
       " 'across': 132,\n",
       " 'states': 133,\n",
       " 'cities': 134,\n",
       " 'tool': 135,\n",
       " 'tips': 136,\n",
       " 'insights': 137,\n",
       " 'contributing': 138,\n",
       " 'strategic': 139,\n",
       " 'predictor': 140,\n",
       " 'llms': 141,\n",
       " 'developed': 142,\n",
       " 'llm': 143,\n",
       " 'predicting': 144,\n",
       " 'se': 145,\n",
       " 'quences': 146,\n",
       " 'modelling': 147,\n",
       " 'used': 148,\n",
       " 'implement': 149,\n",
       " 'incorporating': 150,\n",
       " 'embedding': 151,\n",
       " 'softmax': 152,\n",
       " 'achieve': 153,\n",
       " 'high': 154,\n",
       " 'accuracy': 155,\n",
       " 'through': 156,\n",
       " 'hyper': 157,\n",
       " 'parameter': 158,\n",
       " 'tuning': 159,\n",
       " 'technical': 160,\n",
       " 'skills': 161,\n",
       " 'languages': 162,\n",
       " 'libraries': 163,\n",
       " 'python': 164,\n",
       " 'numpy': 165,\n",
       " 'matplotlib': 166,\n",
       " 'scikit': 167,\n",
       " 'learn': 168,\n",
       " 'seaborn': 169,\n",
       " 'streamlit': 170,\n",
       " 'sql': 171,\n",
       " 'developer': 172,\n",
       " 'tools': 173,\n",
       " 'git': 174,\n",
       " 'github': 175,\n",
       " 'pycharm': 176,\n",
       " 'jupyter': 177,\n",
       " 'notebook': 178,\n",
       " 'colab': 179,\n",
       " 'vs': 180,\n",
       " 'code': 181,\n",
       " 'genai': 182,\n",
       " 'coursework': 183,\n",
       " '–': 184,\n",
       " 'image': 185,\n",
       " 'pattern': 186,\n",
       " 'recognition–': 187,\n",
       " 'processing–': 188,\n",
       " 'mining–': 189,\n",
       " 'operating': 190,\n",
       " 'base': 191,\n",
       " 'management': 192,\n",
       " 'positions': 193,\n",
       " 'responsibility': 194,\n",
       " 'event': 195,\n",
       " 'organizer': 196,\n",
       " 'sports': 197,\n",
       " 'adventure': 198,\n",
       " 'club': 199,\n",
       " 'senior': 200,\n",
       " 'executive': 201,\n",
       " 'dhwani': 202,\n",
       " 'certifications': 203,\n",
       " 'achievements': 204,\n",
       " 'accreditation': 205,\n",
       " 'showcasing': 206,\n",
       " 'proficiency': 207,\n",
       " 'visualization': 208,\n",
       " 'informed': 209,\n",
       " 'udemy’s': 210,\n",
       " 'accomplished': 211,\n",
       " '21': 212,\n",
       " 'days': 213,\n",
       " 'udemy': 214,\n",
       " 'applying': 215,\n",
       " 'algorithms': 216,\n",
       " 'real': 217,\n",
       " 'world': 218,\n",
       " 'datasets': 219,\n",
       " 'united': 220,\n",
       " 'nations': 221,\n",
       " 'recieved': 222,\n",
       " 'verbal': 223,\n",
       " 'unhrc': 224,\n",
       " 'committee': 225,\n",
       " '2': 226,\n",
       " 'consecutive': 227,\n",
       " 'years': 228}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17aa6821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7466edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saandhil Agarwal\n",
      " Bachelor of Technology\n",
      " Information Technology\n",
      " Birla Institute of Technology, Mesra\n",
      " \n",
      "Education\n",
      " Birla Institute of Technology, Mesra\n",
      " B.Tech in Information Technology\n",
      " New Look Uchtar Madhyamik Vidyalaya, Kota\n",
      " Central Board of Secondary Education\n",
      " \n",
      "Experience\n",
      " YHills\n",
      " Campus Ambassador\n",
      " Organized and managed with a group of students for the smooth enrollment of students in courses\n",
      " Addressed queries,implemented innovative strategies and increased student engagement significantly\n",
      " \n",
      "Personal Projects\n",
      " AI Powered Movie Recommender System (Machine Learning)\n",
      " Applied comprehensive feature engineering techniques including feature transformation, feature extraction and One Hot\n",
      " Encoding along with pandas profiling for thorough data analysis. Utilized text vectorization, cosine similarities and\n",
      " integrated APIs with streamlit’s interactive widgets with effortless deployment for movie recommendation\n",
      "Beverage Vista- A sales dashboard of refreshment drinks (Power BI)\n",
      " Leveraged Power BI for detailed analytics in American beverage sales along with dynamic charts using filters & slices.\n",
      " Explored trends across states and cities and implemented tool tips for insights contributing to strategic decision-making\n",
      " Next Word Predictor using LSTM and LLMs (Deep Learning, NLP)\n",
      " Developed a Natural Language Processing Model using LSTM & LLM techniques for predicting the next word in text se\n",
      "quences using language modelling. Used Keras, PyTorch and TensorFlow frameworks to implement the model incorporating\n",
      " embedding layers, LSTM and Softmax layers to achieve high accuracy through hyper-parameter tuning.\n",
      "\n",
      "\n",
      "Technical Skills and Interests\n",
      " Languages and Libraries: Python, C/C++, Numpy, Pandas, Matplotlib, Scikit-learn, Seaborn, Streamlit, SQL\n",
      " Developer Tools: Git/GitHub, Pycharm, Power BI, Jupyter Notebook, Google Colab, VS-Code\n",
      " Frameworks: Keras, TensorFlow, PyTorch\n",
      " Interests: Machine Learning, Deep Learning, NLP, GenAI\n",
      " Coursework:– Image Processing and Pattern Recognition– Natural Language Processing– Data Mining– Operating Systems and Data Base Management Systems\n",
      " \n",
      " Positions of Responsibility\n",
      " Event Organizer, Sports and Adventure Club, BIT Mesra\n",
      " Senior Executive, Dhwani, BIT Mesra\n",
      " \n",
      " Certifications and Achievements\n",
      " Google Analytics Accreditation\n",
      " Showcasing proficiency in data analysis and visualization for informed decision making\n",
      "Udemy’s Machine Learning Course\n",
      " Accomplished a comprehensive \"Machine Learning in 21 days\" course on Udemy applying algorithms on real world datasets\n",
      " Special Mention in Model United Nations\n",
      " Recieved a Special Mention and a Verbal Mention in the UNHRC Committee for 2 consecutive years\n"
     ]
    }
   ],
   "source": [
    "for sentence in faqs.split('\\n'):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5c9b354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 60]\n",
      "[61, 2, 7]\n",
      "[22, 7]\n",
      "[23, 24, 2, 7, 9]\n",
      "[]\n",
      "[25]\n",
      "[23, 24, 2, 7, 9]\n",
      "[62, 63, 3, 22, 7]\n",
      "[64, 65, 66, 67, 68, 69]\n",
      "[70, 71, 2, 72, 25]\n",
      "[]\n",
      "[73]\n",
      "[74]\n",
      "[75, 76]\n",
      "[77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80, 81, 2, 26, 3, 82]\n",
      "[83, 84, 27, 85, 86, 1, 87, 88, 89, 90]\n",
      "[]\n",
      "[91, 92]\n",
      "[93, 94, 28, 95, 96, 11, 6]\n",
      "[97, 29, 14, 98, 30, 99, 14, 100, 14, 101, 1, 102, 103]\n",
      "[104, 31, 8, 32, 105, 4, 106, 12, 33, 107, 34, 108, 109, 110, 1]\n",
      "[111, 112, 8, 113, 114, 115, 8, 116, 117, 4, 28, 118]\n",
      "[35, 119, 5, 36, 120, 2, 121, 122, 15, 16]\n",
      "[123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8, 126, 127, 13, 128, 129]\n",
      "[130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137, 138, 17, 139, 38, 39]\n",
      "[40, 41, 140, 13, 18, 1, 141, 42, 6, 43]\n",
      "[142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10, 40, 41, 3, 34, 145]\n",
      "[146, 13, 19, 147, 148, 46, 47, 1, 48, 49, 17, 149, 10, 20, 150]\n",
      "[151, 50, 18, 1, 152, 50, 17, 153, 154, 155, 156, 157, 158, 159]\n",
      "[]\n",
      "[]\n",
      "[160, 161, 1, 51]\n",
      "[162, 1, 163, 164, 52, 52, 165, 32, 166, 167, 168, 169, 170, 171]\n",
      "[172, 173, 174, 175, 176, 15, 16, 177, 178, 53, 179, 180, 181]\n",
      "[49, 46, 48, 47]\n",
      "[51, 11, 6, 42, 6, 43, 182]\n",
      "[183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189, 190, 54, 1, 12, 191, 192, 54]\n",
      "[]\n",
      "[193, 2, 194]\n",
      "[195, 196, 197, 1, 198, 199, 55, 9]\n",
      "[200, 201, 202, 55, 9]\n",
      "[]\n",
      "[203, 1, 204]\n",
      "[53, 37, 205]\n",
      "[206, 207, 3, 12, 33, 1, 208, 4, 209, 38, 39]\n",
      "[210, 11, 6, 56]\n",
      "[211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215, 216, 57, 217, 218, 219]\n",
      "[58, 21, 3, 20, 220, 221]\n",
      "[222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224, 225, 4, 226, 227, 228]\n"
     ]
    }
   ],
   "source": [
    "for sentence in faqs.split('\\n'):\n",
    "    print(tokenizer.texts_to_sequences([sentence])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c6ed7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for sentence in faqs.split('\\n'):\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    for i in range(1, len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "102f0879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[59, 60],\n",
       " [61, 2],\n",
       " [61, 2, 7],\n",
       " [22, 7],\n",
       " [23, 24],\n",
       " [23, 24, 2],\n",
       " [23, 24, 2, 7],\n",
       " [23, 24, 2, 7, 9],\n",
       " [23, 24],\n",
       " [23, 24, 2],\n",
       " [23, 24, 2, 7],\n",
       " [23, 24, 2, 7, 9],\n",
       " [62, 63],\n",
       " [62, 63, 3],\n",
       " [62, 63, 3, 22],\n",
       " [62, 63, 3, 22, 7],\n",
       " [64, 65],\n",
       " [64, 65, 66],\n",
       " [64, 65, 66, 67],\n",
       " [64, 65, 66, 67, 68],\n",
       " [64, 65, 66, 67, 68, 69],\n",
       " [70, 71],\n",
       " [70, 71, 2],\n",
       " [70, 71, 2, 72],\n",
       " [70, 71, 2, 72, 25],\n",
       " [75, 76],\n",
       " [77, 1],\n",
       " [77, 1, 78],\n",
       " [77, 1, 78, 8],\n",
       " [77, 1, 78, 8, 5],\n",
       " [77, 1, 78, 8, 5, 79],\n",
       " [77, 1, 78, 8, 5, 79, 2],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80, 81],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80, 81, 2],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80, 81, 2, 26],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80, 81, 2, 26, 3],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80, 81, 2, 26, 3, 82],\n",
       " [83, 84],\n",
       " [83, 84, 27],\n",
       " [83, 84, 27, 85],\n",
       " [83, 84, 27, 85, 86],\n",
       " [83, 84, 27, 85, 86, 1],\n",
       " [83, 84, 27, 85, 86, 1, 87],\n",
       " [83, 84, 27, 85, 86, 1, 87, 88],\n",
       " [83, 84, 27, 85, 86, 1, 87, 88, 89],\n",
       " [83, 84, 27, 85, 86, 1, 87, 88, 89, 90],\n",
       " [91, 92],\n",
       " [93, 94],\n",
       " [93, 94, 28],\n",
       " [93, 94, 28, 95],\n",
       " [93, 94, 28, 95, 96],\n",
       " [93, 94, 28, 95, 96, 11],\n",
       " [93, 94, 28, 95, 96, 11, 6],\n",
       " [97, 29],\n",
       " [97, 29, 14],\n",
       " [97, 29, 14, 98],\n",
       " [97, 29, 14, 98, 30],\n",
       " [97, 29, 14, 98, 30, 99],\n",
       " [97, 29, 14, 98, 30, 99, 14],\n",
       " [97, 29, 14, 98, 30, 99, 14, 100],\n",
       " [97, 29, 14, 98, 30, 99, 14, 100, 14],\n",
       " [97, 29, 14, 98, 30, 99, 14, 100, 14, 101],\n",
       " [97, 29, 14, 98, 30, 99, 14, 100, 14, 101, 1],\n",
       " [97, 29, 14, 98, 30, 99, 14, 100, 14, 101, 1, 102],\n",
       " [97, 29, 14, 98, 30, 99, 14, 100, 14, 101, 1, 102, 103],\n",
       " [104, 31],\n",
       " [104, 31, 8],\n",
       " [104, 31, 8, 32],\n",
       " [104, 31, 8, 32, 105],\n",
       " [104, 31, 8, 32, 105, 4],\n",
       " [104, 31, 8, 32, 105, 4, 106],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33, 107],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33, 107, 34],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33, 107, 34, 108],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33, 107, 34, 108, 109],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33, 107, 34, 108, 109, 110],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33, 107, 34, 108, 109, 110, 1],\n",
       " [111, 112],\n",
       " [111, 112, 8],\n",
       " [111, 112, 8, 113],\n",
       " [111, 112, 8, 113, 114],\n",
       " [111, 112, 8, 113, 114, 115],\n",
       " [111, 112, 8, 113, 114, 115, 8],\n",
       " [111, 112, 8, 113, 114, 115, 8, 116],\n",
       " [111, 112, 8, 113, 114, 115, 8, 116, 117],\n",
       " [111, 112, 8, 113, 114, 115, 8, 116, 117, 4],\n",
       " [111, 112, 8, 113, 114, 115, 8, 116, 117, 4, 28],\n",
       " [111, 112, 8, 113, 114, 115, 8, 116, 117, 4, 28, 118],\n",
       " [35, 119],\n",
       " [35, 119, 5],\n",
       " [35, 119, 5, 36],\n",
       " [35, 119, 5, 36, 120],\n",
       " [35, 119, 5, 36, 120, 2],\n",
       " [35, 119, 5, 36, 120, 2, 121],\n",
       " [35, 119, 5, 36, 120, 2, 121, 122],\n",
       " [35, 119, 5, 36, 120, 2, 121, 122, 15],\n",
       " [35, 119, 5, 36, 120, 2, 121, 122, 15, 16],\n",
       " [123, 15],\n",
       " [123, 15, 16],\n",
       " [123, 15, 16, 4],\n",
       " [123, 15, 16, 4, 124],\n",
       " [123, 15, 16, 4, 124, 37],\n",
       " [123, 15, 16, 4, 124, 37, 3],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8, 126],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8, 126, 127],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8, 126, 127, 13],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8, 126, 127, 13, 128],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8, 126, 127, 13, 128, 129],\n",
       " [130, 131],\n",
       " [130, 131, 132],\n",
       " [130, 131, 132, 133],\n",
       " [130, 131, 132, 133, 1],\n",
       " [130, 131, 132, 133, 1, 134],\n",
       " [130, 131, 132, 133, 1, 134, 1],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137, 138],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137, 138, 17],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137, 138, 17, 139],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137, 138, 17, 139, 38],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137, 138, 17, 139, 38, 39],\n",
       " [40, 41],\n",
       " [40, 41, 140],\n",
       " [40, 41, 140, 13],\n",
       " [40, 41, 140, 13, 18],\n",
       " [40, 41, 140, 13, 18, 1],\n",
       " [40, 41, 140, 13, 18, 1, 141],\n",
       " [40, 41, 140, 13, 18, 1, 141, 42],\n",
       " [40, 41, 140, 13, 18, 1, 141, 42, 6],\n",
       " [40, 41, 140, 13, 18, 1, 141, 42, 6, 43],\n",
       " [142, 5],\n",
       " [142, 5, 44],\n",
       " [142, 5, 44, 19],\n",
       " [142, 5, 44, 19, 45],\n",
       " [142, 5, 44, 19, 45, 20],\n",
       " [142, 5, 44, 19, 45, 20, 13],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10, 40],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10, 40, 41],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10, 40, 41, 3],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10, 40, 41, 3, 34],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10, 40, 41, 3, 34, 145],\n",
       " [146, 13],\n",
       " [146, 13, 19],\n",
       " [146, 13, 19, 147],\n",
       " [146, 13, 19, 147, 148],\n",
       " [146, 13, 19, 147, 148, 46],\n",
       " [146, 13, 19, 147, 148, 46, 47],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48, 49],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48, 49, 17],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48, 49, 17, 149],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48, 49, 17, 149, 10],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48, 49, 17, 149, 10, 20],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48, 49, 17, 149, 10, 20, 150],\n",
       " [151, 50],\n",
       " [151, 50, 18],\n",
       " [151, 50, 18, 1],\n",
       " [151, 50, 18, 1, 152],\n",
       " [151, 50, 18, 1, 152, 50],\n",
       " [151, 50, 18, 1, 152, 50, 17],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153, 154],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153, 154, 155],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153, 154, 155, 156],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153, 154, 155, 156, 157],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153, 154, 155, 156, 157, 158],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153, 154, 155, 156, 157, 158, 159],\n",
       " [160, 161],\n",
       " [160, 161, 1],\n",
       " [160, 161, 1, 51],\n",
       " [162, 1],\n",
       " [162, 1, 163],\n",
       " [162, 1, 163, 164],\n",
       " [162, 1, 163, 164, 52],\n",
       " [162, 1, 163, 164, 52, 52],\n",
       " [162, 1, 163, 164, 52, 52, 165],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32, 166],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32, 166, 167],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32, 166, 167, 168],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32, 166, 167, 168, 169],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32, 166, 167, 168, 169, 170],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32, 166, 167, 168, 169, 170, 171],\n",
       " [172, 173],\n",
       " [172, 173, 174],\n",
       " [172, 173, 174, 175],\n",
       " [172, 173, 174, 175, 176],\n",
       " [172, 173, 174, 175, 176, 15],\n",
       " [172, 173, 174, 175, 176, 15, 16],\n",
       " [172, 173, 174, 175, 176, 15, 16, 177],\n",
       " [172, 173, 174, 175, 176, 15, 16, 177, 178],\n",
       " [172, 173, 174, 175, 176, 15, 16, 177, 178, 53],\n",
       " [172, 173, 174, 175, 176, 15, 16, 177, 178, 53, 179],\n",
       " [172, 173, 174, 175, 176, 15, 16, 177, 178, 53, 179, 180],\n",
       " [172, 173, 174, 175, 176, 15, 16, 177, 178, 53, 179, 180, 181],\n",
       " [49, 46],\n",
       " [49, 46, 48],\n",
       " [49, 46, 48, 47],\n",
       " [51, 11],\n",
       " [51, 11, 6],\n",
       " [51, 11, 6, 42],\n",
       " [51, 11, 6, 42, 6],\n",
       " [51, 11, 6, 42, 6, 43],\n",
       " [51, 11, 6, 42, 6, 43, 182],\n",
       " [183, 184],\n",
       " [183, 184, 185],\n",
       " [183, 184, 185, 45],\n",
       " [183, 184, 185, 45, 1],\n",
       " [183, 184, 185, 45, 1, 186],\n",
       " [183, 184, 185, 45, 1, 186, 187],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189, 190],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189, 190, 54],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189, 190, 54, 1],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189, 190, 54, 1, 12],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189, 190, 54, 1, 12, 191],\n",
       " [183,\n",
       "  184,\n",
       "  185,\n",
       "  45,\n",
       "  1,\n",
       "  186,\n",
       "  187,\n",
       "  44,\n",
       "  19,\n",
       "  188,\n",
       "  12,\n",
       "  189,\n",
       "  190,\n",
       "  54,\n",
       "  1,\n",
       "  12,\n",
       "  191,\n",
       "  192],\n",
       " [183,\n",
       "  184,\n",
       "  185,\n",
       "  45,\n",
       "  1,\n",
       "  186,\n",
       "  187,\n",
       "  44,\n",
       "  19,\n",
       "  188,\n",
       "  12,\n",
       "  189,\n",
       "  190,\n",
       "  54,\n",
       "  1,\n",
       "  12,\n",
       "  191,\n",
       "  192,\n",
       "  54],\n",
       " [193, 2],\n",
       " [193, 2, 194],\n",
       " [195, 196],\n",
       " [195, 196, 197],\n",
       " [195, 196, 197, 1],\n",
       " [195, 196, 197, 1, 198],\n",
       " [195, 196, 197, 1, 198, 199],\n",
       " [195, 196, 197, 1, 198, 199, 55],\n",
       " [195, 196, 197, 1, 198, 199, 55, 9],\n",
       " [200, 201],\n",
       " [200, 201, 202],\n",
       " [200, 201, 202, 55],\n",
       " [200, 201, 202, 55, 9],\n",
       " [203, 1],\n",
       " [203, 1, 204],\n",
       " [53, 37],\n",
       " [53, 37, 205],\n",
       " [206, 207],\n",
       " [206, 207, 3],\n",
       " [206, 207, 3, 12],\n",
       " [206, 207, 3, 12, 33],\n",
       " [206, 207, 3, 12, 33, 1],\n",
       " [206, 207, 3, 12, 33, 1, 208],\n",
       " [206, 207, 3, 12, 33, 1, 208, 4],\n",
       " [206, 207, 3, 12, 33, 1, 208, 4, 209],\n",
       " [206, 207, 3, 12, 33, 1, 208, 4, 209, 38],\n",
       " [206, 207, 3, 12, 33, 1, 208, 4, 209, 38, 39],\n",
       " [210, 11],\n",
       " [210, 11, 6],\n",
       " [210, 11, 6, 56],\n",
       " [211, 5],\n",
       " [211, 5, 29],\n",
       " [211, 5, 29, 11],\n",
       " [211, 5, 29, 11, 6],\n",
       " [211, 5, 29, 11, 6, 3],\n",
       " [211, 5, 29, 11, 6, 3, 212],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215, 216],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215, 216, 57],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215, 216, 57, 217],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215, 216, 57, 217, 218],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215, 216, 57, 217, 218, 219],\n",
       " [58, 21],\n",
       " [58, 21, 3],\n",
       " [58, 21, 3, 20],\n",
       " [58, 21, 3, 20, 220],\n",
       " [58, 21, 3, 20, 220, 221],\n",
       " [222, 5],\n",
       " [222, 5, 58],\n",
       " [222, 5, 58, 21],\n",
       " [222, 5, 58, 21, 1],\n",
       " [222, 5, 58, 21, 1, 5],\n",
       " [222, 5, 58, 21, 1, 5, 223],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224, 225],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224, 225, 4],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224, 225, 4, 226],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224, 225, 4, 226, 227],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224, 225, 4, 226, 227, 228]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee9ea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db5019a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a9b8ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35963f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences=pad_sequences(input_sequences, maxlen =max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0750b583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  59,  60],\n",
       "       [  0,   0,   0, ...,   0,  61,   2],\n",
       "       [  0,   0,   0, ...,  61,   2,   7],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 225,   4, 226],\n",
       "       [  0,   0,   0, ...,   4, 226, 227],\n",
       "       [  0,   0,   0, ..., 226, 227, 228]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0871a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=padded_input_sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92fccda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1dbb078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 18)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bfaa1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccf803f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y=to_categorical(y,num_classes=229)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3e89264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 229)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d7c749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c3fdd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(229,100,input_length=18))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(229,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6073321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d751ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 18, 100)           22900     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 150)               150600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 229)               34579     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 208079 (812.81 KB)\n",
      "Trainable params: 208079 (812.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0195001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,  59],\n",
       "       [  0,   0,   0, ...,   0,   0,  61],\n",
       "       [  0,   0,   0, ...,   0,  61,   2],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 224, 225,   4],\n",
       "       [  0,   0,   0, ..., 225,   4, 226],\n",
       "       [  0,   0,   0, ...,   4, 226, 227]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c72ecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 2s 12ms/step - loss: 5.4304 - accuracy: 0.0162\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 5.3224 - accuracy: 0.0550\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 5.1689 - accuracy: 0.0550\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 5.0774 - accuracy: 0.0550\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 5.0220 - accuracy: 0.0550\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4.9624 - accuracy: 0.0550\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4.8956 - accuracy: 0.0550\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4.8288 - accuracy: 0.0485\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 4.7336 - accuracy: 0.0615\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4.6557 - accuracy: 0.0647\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4.5804 - accuracy: 0.0615\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 4.4820 - accuracy: 0.0680\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4.3922 - accuracy: 0.0777\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4.2740 - accuracy: 0.1068\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4.1642 - accuracy: 0.1262\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4.0357 - accuracy: 0.1424\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3.9093 - accuracy: 0.1650\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3.7857 - accuracy: 0.1683\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3.6806 - accuracy: 0.2071\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3.5498 - accuracy: 0.2168\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3.4255 - accuracy: 0.2265\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3.2857 - accuracy: 0.2718\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3.1641 - accuracy: 0.2913\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.0384 - accuracy: 0.3301\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2.9251 - accuracy: 0.3366\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2.8012 - accuracy: 0.3883\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2.6901 - accuracy: 0.4110\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2.5804 - accuracy: 0.4531\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2.4822 - accuracy: 0.4628\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2.3983 - accuracy: 0.4304\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2.2779 - accuracy: 0.5146\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2.1820 - accuracy: 0.5437\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 2.0924 - accuracy: 0.5469\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 2.0250 - accuracy: 0.5307\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.9710 - accuracy: 0.5793\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.9138 - accuracy: 0.5728\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.8293 - accuracy: 0.6084\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7853 - accuracy: 0.6019\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.6694 - accuracy: 0.6634\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.5936 - accuracy: 0.7087\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.5399 - accuracy: 0.7249\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.4647 - accuracy: 0.7508\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.4050 - accuracy: 0.7670\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3474 - accuracy: 0.7767\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2886 - accuracy: 0.8091\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2261 - accuracy: 0.8123\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1788 - accuracy: 0.8123\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.1337 - accuracy: 0.8414\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0937 - accuracy: 0.8511\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.0526 - accuracy: 0.8673\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0109 - accuracy: 0.8867\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9849 - accuracy: 0.8964\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9384 - accuracy: 0.8997\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9153 - accuracy: 0.9191\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8704 - accuracy: 0.9385\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8262 - accuracy: 0.9288\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7861 - accuracy: 0.9579\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7562 - accuracy: 0.9644\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7435 - accuracy: 0.9579\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7179 - accuracy: 0.9644\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6827 - accuracy: 0.9773\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6432 - accuracy: 0.9709\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6172 - accuracy: 0.9806\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5995 - accuracy: 0.9806\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5751 - accuracy: 0.9838\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5566 - accuracy: 0.9838\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5320 - accuracy: 0.9838\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5146 - accuracy: 0.9838\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4866 - accuracy: 0.9903\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4631 - accuracy: 0.9903\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4545 - accuracy: 0.9935\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4470 - accuracy: 0.9968\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4286 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4588 - accuracy: 0.9806\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4251 - accuracy: 0.9903\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3845 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3629 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3426 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.3284 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3150 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3039 - accuracy: 1.0000\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2941 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2838 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2731 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2639 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2537 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2456 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2384 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2297 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2225 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2138 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2067 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2003 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1940 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1894 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1834 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1773 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1723 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1665 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1638 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ad5e7d13a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a11110f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Birla\"\n",
    "#tokenize\n",
    "token_text=tokenizer.texts_to_sequences([text])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20134ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23]]\n"
     ]
    }
   ],
   "source": [
    "#padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_text=pad_sequences([token_text],maxlen=18,padding='pre')\n",
    "print(padded_input_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a545d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 363ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.12876818e-07, 6.46784320e-04, 1.77913792e-02, 3.16574215e-03,\n",
       "        1.93364085e-05, 1.93819273e-04, 5.13899176e-05, 2.18510279e-03,\n",
       "        4.36847995e-06, 3.12293385e-04, 3.96327141e-06, 1.42812409e-04,\n",
       "        2.01001640e-05, 3.47979862e-04, 1.39749711e-04, 6.59561977e-07,\n",
       "        2.69195738e-07, 1.85360693e-06, 2.30563478e-06, 5.26767217e-05,\n",
       "        2.50080921e-05, 3.70261201e-04, 7.50894151e-06, 2.44908279e-07,\n",
       "        9.28039670e-01, 8.33465219e-06, 1.98169819e-05, 1.71096599e-06,\n",
       "        7.17878575e-05, 2.79009255e-04, 1.17314348e-05, 3.51149683e-05,\n",
       "        1.06636537e-06, 6.87312740e-06, 5.96481777e-06, 1.21210246e-06,\n",
       "        1.98355301e-05, 1.04548679e-04, 7.85068369e-06, 4.12458257e-06,\n",
       "        5.55063525e-06, 8.78723513e-04, 4.32483876e-06, 1.76996593e-06,\n",
       "        3.20852851e-04, 1.33884279e-03, 4.24756618e-05, 3.31203387e-06,\n",
       "        1.69063533e-05, 3.11834310e-06, 2.25201006e-06, 3.31890333e-05,\n",
       "        2.60028976e-08, 1.34672263e-07, 4.27097302e-06, 1.11972193e-04,\n",
       "        4.75638808e-06, 1.55416035e-06, 2.26480581e-04, 2.90859930e-07,\n",
       "        1.84340263e-03, 3.71244624e-07, 4.04285231e-07, 4.55497252e-03,\n",
       "        2.72062834e-07, 3.95438219e-05, 9.49760670e-06, 1.58248451e-06,\n",
       "        2.56353445e-07, 1.80700312e-07, 2.58871637e-07, 1.09830755e-03,\n",
       "        5.48563621e-05, 2.60754234e-07, 4.21887393e-07, 1.56919583e-07,\n",
       "        2.14828688e-04, 6.08213554e-07, 1.83672728e-05, 1.49709012e-05,\n",
       "        4.79730170e-06, 2.34724612e-05, 8.21996309e-06, 3.47650911e-07,\n",
       "        1.01384932e-04, 1.26639338e-06, 6.42313296e-07, 1.68506824e-06,\n",
       "        3.32622278e-07, 2.71042904e-06, 2.09370100e-07, 3.39514713e-07,\n",
       "        1.92969655e-05, 5.60989463e-07, 1.29089563e-03, 1.49423257e-04,\n",
       "        2.19119192e-05, 2.52893216e-07, 1.66643204e-05, 9.05862237e-07,\n",
       "        1.50604228e-06, 1.83576674e-06, 1.29568593e-06, 2.03268314e-06,\n",
       "        5.41008433e-07, 6.68196435e-07, 1.20446557e-05, 3.97741360e-06,\n",
       "        4.08249798e-06, 4.60465390e-06, 1.36888975e-05, 1.67241822e-07,\n",
       "        1.22595129e-05, 3.47525599e-07, 1.77537316e-07, 5.92628385e-06,\n",
       "        2.47238722e-06, 8.82062977e-07, 4.67827294e-06, 3.10234929e-04,\n",
       "        1.10975070e-05, 1.02853573e-05, 5.44256238e-07, 4.40702081e-07,\n",
       "        2.03315403e-06, 1.44524222e-06, 9.96252766e-07, 2.75426737e-06,\n",
       "        2.02754291e-06, 8.53521101e-07, 2.40870008e-07, 5.16219623e-03,\n",
       "        2.53572449e-04, 8.13581719e-05, 8.24893675e-07, 1.15152693e-06,\n",
       "        1.41170267e-06, 9.63512207e-07, 6.39689006e-07, 1.47947003e-06,\n",
       "        7.05081737e-04, 1.04267087e-06, 4.52302885e-07, 1.12155312e-05,\n",
       "        3.31038541e-06, 6.84382883e-07, 2.02232968e-07, 3.26527115e-05,\n",
       "        2.71253634e-06, 1.78394851e-06, 1.51561949e-06, 3.84255230e-07,\n",
       "        1.26561147e-07, 3.34826581e-07, 3.11605220e-07, 2.08709636e-07,\n",
       "        2.79990275e-07, 5.60260219e-07, 5.29346607e-07, 2.84536753e-07,\n",
       "        1.59651762e-07, 1.08351524e-03, 2.62792071e-07, 3.32769014e-06,\n",
       "        2.86201054e-08, 1.80365802e-07, 6.34332650e-07, 8.19350205e-08,\n",
       "        6.43754447e-07, 6.24408301e-07, 1.41299972e-06, 2.40440841e-07,\n",
       "        2.31406190e-07, 6.93820721e-06, 2.47967279e-07, 1.78852645e-07,\n",
       "        3.48411646e-07, 5.19652929e-07, 1.99149653e-07, 2.12899153e-07,\n",
       "        4.39142212e-07, 4.84362431e-07, 1.22497829e-06, 7.28575912e-07,\n",
       "        2.00288314e-02, 2.47917185e-03, 5.27271050e-06, 2.36969299e-05,\n",
       "        1.95882731e-05, 1.38933055e-05, 2.77871936e-06, 1.81072528e-06,\n",
       "        2.33208334e-06, 7.14670023e-07, 1.17693737e-04, 5.11703320e-07,\n",
       "        1.11289264e-03, 8.48440031e-05, 6.13040220e-06, 9.24531196e-06,\n",
       "        1.61753050e-07, 1.00098900e-03, 1.26575105e-04, 1.99366667e-07,\n",
       "        3.82007602e-06, 4.83410695e-04, 3.73049318e-07, 5.58540269e-05,\n",
       "        1.75930825e-06, 1.65593246e-06, 7.64406593e-07, 2.26456478e-07,\n",
       "        7.39742703e-08, 4.79943139e-07, 4.43557497e-07, 1.22539831e-07,\n",
       "        1.22452627e-06, 1.30458966e-06, 2.67120322e-06, 4.72800309e-07,\n",
       "        3.46367733e-06, 6.95733320e-07, 3.03221043e-07, 3.17113108e-06,\n",
       "        1.64281403e-06, 7.09084077e-07, 1.73512603e-06, 2.34087383e-06,\n",
       "        3.24211828e-06]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "model.predict(padded_input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea3e7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 229)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_input_text).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a25c8a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(model.predict(padded_input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1b17886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 1,\n",
       " 'of': 2,\n",
       " 'in': 3,\n",
       " 'for': 4,\n",
       " 'a': 5,\n",
       " 'learning': 6,\n",
       " 'technology': 7,\n",
       " 'with': 8,\n",
       " 'mesra': 9,\n",
       " 'the': 10,\n",
       " 'machine': 11,\n",
       " 'data': 12,\n",
       " 'using': 13,\n",
       " 'feature': 14,\n",
       " 'power': 15,\n",
       " 'bi': 16,\n",
       " 'to': 17,\n",
       " 'lstm': 18,\n",
       " 'language': 19,\n",
       " 'model': 20,\n",
       " 'mention': 21,\n",
       " 'information': 22,\n",
       " 'birla': 23,\n",
       " 'institute': 24,\n",
       " 'education': 25,\n",
       " 'students': 26,\n",
       " 'implemented': 27,\n",
       " 'movie': 28,\n",
       " 'comprehensive': 29,\n",
       " 'techniques': 30,\n",
       " 'along': 31,\n",
       " 'pandas': 32,\n",
       " 'analysis': 33,\n",
       " 'text': 34,\n",
       " 'beverage': 35,\n",
       " 'sales': 36,\n",
       " 'analytics': 37,\n",
       " 'decision': 38,\n",
       " 'making': 39,\n",
       " 'next': 40,\n",
       " 'word': 41,\n",
       " 'deep': 42,\n",
       " 'nlp': 43,\n",
       " 'natural': 44,\n",
       " 'processing': 45,\n",
       " 'keras': 46,\n",
       " 'pytorch': 47,\n",
       " 'tensorflow': 48,\n",
       " 'frameworks': 49,\n",
       " 'layers': 50,\n",
       " 'interests': 51,\n",
       " 'c': 52,\n",
       " 'google': 53,\n",
       " 'systems': 54,\n",
       " 'bit': 55,\n",
       " 'course': 56,\n",
       " 'on': 57,\n",
       " 'special': 58,\n",
       " 'saandhil': 59,\n",
       " 'agarwal': 60,\n",
       " 'bachelor': 61,\n",
       " 'b': 62,\n",
       " 'tech': 63,\n",
       " 'new': 64,\n",
       " 'look': 65,\n",
       " 'uchtar': 66,\n",
       " 'madhyamik': 67,\n",
       " 'vidyalaya': 68,\n",
       " 'kota': 69,\n",
       " 'central': 70,\n",
       " 'board': 71,\n",
       " 'secondary': 72,\n",
       " 'experience': 73,\n",
       " 'yhills': 74,\n",
       " 'campus': 75,\n",
       " 'ambassador': 76,\n",
       " 'organized': 77,\n",
       " 'managed': 78,\n",
       " 'group': 79,\n",
       " 'smooth': 80,\n",
       " 'enrollment': 81,\n",
       " 'courses': 82,\n",
       " 'addressed': 83,\n",
       " 'queries': 84,\n",
       " 'innovative': 85,\n",
       " 'strategies': 86,\n",
       " 'increased': 87,\n",
       " 'student': 88,\n",
       " 'engagement': 89,\n",
       " 'significantly': 90,\n",
       " 'personal': 91,\n",
       " 'projects': 92,\n",
       " 'ai': 93,\n",
       " 'powered': 94,\n",
       " 'recommender': 95,\n",
       " 'system': 96,\n",
       " 'applied': 97,\n",
       " 'engineering': 98,\n",
       " 'including': 99,\n",
       " 'transformation': 100,\n",
       " 'extraction': 101,\n",
       " 'one': 102,\n",
       " 'hot': 103,\n",
       " 'encoding': 104,\n",
       " 'profiling': 105,\n",
       " 'thorough': 106,\n",
       " 'utilized': 107,\n",
       " 'vectorization': 108,\n",
       " 'cosine': 109,\n",
       " 'similarities': 110,\n",
       " 'integrated': 111,\n",
       " 'apis': 112,\n",
       " 'streamlit’s': 113,\n",
       " 'interactive': 114,\n",
       " 'widgets': 115,\n",
       " 'effortless': 116,\n",
       " 'deployment': 117,\n",
       " 'recommendation': 118,\n",
       " 'vista': 119,\n",
       " 'dashboard': 120,\n",
       " 'refreshment': 121,\n",
       " 'drinks': 122,\n",
       " 'leveraged': 123,\n",
       " 'detailed': 124,\n",
       " 'american': 125,\n",
       " 'dynamic': 126,\n",
       " 'charts': 127,\n",
       " 'filters': 128,\n",
       " 'slices': 129,\n",
       " 'explored': 130,\n",
       " 'trends': 131,\n",
       " 'across': 132,\n",
       " 'states': 133,\n",
       " 'cities': 134,\n",
       " 'tool': 135,\n",
       " 'tips': 136,\n",
       " 'insights': 137,\n",
       " 'contributing': 138,\n",
       " 'strategic': 139,\n",
       " 'predictor': 140,\n",
       " 'llms': 141,\n",
       " 'developed': 142,\n",
       " 'llm': 143,\n",
       " 'predicting': 144,\n",
       " 'se': 145,\n",
       " 'quences': 146,\n",
       " 'modelling': 147,\n",
       " 'used': 148,\n",
       " 'implement': 149,\n",
       " 'incorporating': 150,\n",
       " 'embedding': 151,\n",
       " 'softmax': 152,\n",
       " 'achieve': 153,\n",
       " 'high': 154,\n",
       " 'accuracy': 155,\n",
       " 'through': 156,\n",
       " 'hyper': 157,\n",
       " 'parameter': 158,\n",
       " 'tuning': 159,\n",
       " 'technical': 160,\n",
       " 'skills': 161,\n",
       " 'languages': 162,\n",
       " 'libraries': 163,\n",
       " 'python': 164,\n",
       " 'numpy': 165,\n",
       " 'matplotlib': 166,\n",
       " 'scikit': 167,\n",
       " 'learn': 168,\n",
       " 'seaborn': 169,\n",
       " 'streamlit': 170,\n",
       " 'sql': 171,\n",
       " 'developer': 172,\n",
       " 'tools': 173,\n",
       " 'git': 174,\n",
       " 'github': 175,\n",
       " 'pycharm': 176,\n",
       " 'jupyter': 177,\n",
       " 'notebook': 178,\n",
       " 'colab': 179,\n",
       " 'vs': 180,\n",
       " 'code': 181,\n",
       " 'genai': 182,\n",
       " 'coursework': 183,\n",
       " '–': 184,\n",
       " 'image': 185,\n",
       " 'pattern': 186,\n",
       " 'recognition–': 187,\n",
       " 'processing–': 188,\n",
       " 'mining–': 189,\n",
       " 'operating': 190,\n",
       " 'base': 191,\n",
       " 'management': 192,\n",
       " 'positions': 193,\n",
       " 'responsibility': 194,\n",
       " 'event': 195,\n",
       " 'organizer': 196,\n",
       " 'sports': 197,\n",
       " 'adventure': 198,\n",
       " 'club': 199,\n",
       " 'senior': 200,\n",
       " 'executive': 201,\n",
       " 'dhwani': 202,\n",
       " 'certifications': 203,\n",
       " 'achievements': 204,\n",
       " 'accreditation': 205,\n",
       " 'showcasing': 206,\n",
       " 'proficiency': 207,\n",
       " 'visualization': 208,\n",
       " 'informed': 209,\n",
       " 'udemy’s': 210,\n",
       " 'accomplished': 211,\n",
       " '21': 212,\n",
       " 'days': 213,\n",
       " 'udemy': 214,\n",
       " 'applying': 215,\n",
       " 'algorithms': 216,\n",
       " 'real': 217,\n",
       " 'world': 218,\n",
       " 'datasets': 219,\n",
       " 'united': 220,\n",
       " 'nations': 221,\n",
       " 'recieved': 222,\n",
       " 'verbal': 223,\n",
       " 'unhrc': 224,\n",
       " 'committee': 225,\n",
       " '2': 226,\n",
       " 'consecutive': 227,\n",
       " 'years': 228}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2923900b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "institute\n"
     ]
    }
   ],
   "source": [
    "pos=np.argmax(model.predict(padded_input_text))\n",
    "for word,index in tokenizer.word_index.items():\n",
    "  if index==pos:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea9fdef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "frameworks keras\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "frameworks keras tensorflow\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "frameworks keras tensorflow pytorch\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "frameworks keras tensorflow pytorch and\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "frameworks keras tensorflow pytorch and tensorflow\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text=\"frameworks\"\n",
    " \n",
    "for i in range(5):\n",
    "    #tokenize\n",
    "    token_text=tokenizer.texts_to_sequences([text])[0]\n",
    "    #padding\n",
    "    padded_input_text=pad_sequences([token_text],maxlen=18,padding='pre')\n",
    "    #predict\n",
    "    pos=np.argmax(model.predict(padded_input_text))\n",
    "    \n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if index ==pos:\n",
    "            text=text+ \" \" +word\n",
    "            print(text)\n",
    "            time.sleep(2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c09b732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
