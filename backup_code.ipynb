{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e46a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs=\"\"\"Saandhil Agarwal\n",
    " Bachelor of Technology\n",
    " Information Technology\n",
    " Birla Institute of Technology, Mesra\n",
    " \n",
    "Education\n",
    " Birla Institute of Technology, Mesra\n",
    " B.Tech in Information Technology\n",
    " New Look Uchtar Madhyamik Vidyalaya, Kota\n",
    " Central Board of Secondary Education\n",
    " \n",
    "Experience\n",
    " YHills\n",
    " Campus Ambassador\n",
    " Organized and managed with a group of students for the smooth enrollment of students in courses\n",
    " Addressed queries,implemented innovative strategies and increased student engagement significantly\n",
    " \n",
    "Personal Projects\n",
    " AI Powered Movie Recommender System (Machine Learning)\n",
    " Applied comprehensive feature engineering techniques including feature transformation, feature extraction and One Hot\n",
    " Encoding along with pandas profiling for thorough data analysis. Utilized text vectorization, cosine similarities and\n",
    " integrated APIs with streamlit’s interactive widgets with effortless deployment for movie recommendation\n",
    "Beverage Vista- A sales dashboard of refreshment drinks (Power BI)\n",
    " Leveraged Power BI for detailed analytics in American beverage sales along with dynamic charts using filters & slices.\n",
    " Explored trends across states and cities and implemented tool tips for insights contributing to strategic decision-making\n",
    " Next Word Predictor using LSTM and LLMs (Deep Learning, NLP)\n",
    " Developed a Natural Language Processing Model using LSTM & LLM techniques for predicting the next word in text se\n",
    "quences using language modelling. Used Keras, PyTorch and TensorFlow frameworks to implement the model incorporating\n",
    " embedding layers, LSTM and Softmax layers to achieve high accuracy through hyper-parameter tuning.\n",
    "\n",
    "\n",
    "Technical Skills and Interests\n",
    " Languages and Libraries: Python, C/C++, Numpy, Pandas, Matplotlib, Scikit-learn, Seaborn, Streamlit, SQL\n",
    " Developer Tools: Git/GitHub, Pycharm, Power BI, Jupyter Notebook, Google Colab, VS-Code\n",
    " Frameworks: Keras, TensorFlow, PyTorch\n",
    " Interests: Machine Learning, Deep Learning, NLP, GenAI\n",
    " Coursework:– Image Processing and Pattern Recognition– Natural Language Processing– Data Mining– Operating Systems and Data Base Management Systems\n",
    " \n",
    " Positions of Responsibility\n",
    " Event Organizer, Sports and Adventure Club, BIT Mesra\n",
    " Senior Executive, Dhwani, BIT Mesra\n",
    " \n",
    " Certifications and Achievements\n",
    " Google Analytics Accreditation\n",
    " Showcasing proficiency in data analysis and visualization for informed decision making\n",
    "Udemy’s Machine Learning Course\n",
    " Accomplished a comprehensive \"Machine Learning in 21 days\" course on Udemy applying algorithms on real world datasets\n",
    " Special Mention in Model United Nations\n",
    " Recieved a Special Mention and a Verbal Mention in the UNHRC Committee for 2 consecutive years\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaef4826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saandhil agarwal\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a229be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b9ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([faqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98dba24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 1,\n",
       " 'of': 2,\n",
       " 'in': 3,\n",
       " 'for': 4,\n",
       " 'a': 5,\n",
       " 'learning': 6,\n",
       " 'technology': 7,\n",
       " 'with': 8,\n",
       " 'mesra': 9,\n",
       " 'the': 10,\n",
       " 'machine': 11,\n",
       " 'data': 12,\n",
       " 'using': 13,\n",
       " 'feature': 14,\n",
       " 'power': 15,\n",
       " 'bi': 16,\n",
       " 'to': 17,\n",
       " 'lstm': 18,\n",
       " 'language': 19,\n",
       " 'model': 20,\n",
       " 'mention': 21,\n",
       " 'information': 22,\n",
       " 'birla': 23,\n",
       " 'institute': 24,\n",
       " 'education': 25,\n",
       " 'students': 26,\n",
       " 'implemented': 27,\n",
       " 'movie': 28,\n",
       " 'comprehensive': 29,\n",
       " 'techniques': 30,\n",
       " 'along': 31,\n",
       " 'pandas': 32,\n",
       " 'analysis': 33,\n",
       " 'text': 34,\n",
       " 'beverage': 35,\n",
       " 'sales': 36,\n",
       " 'analytics': 37,\n",
       " 'decision': 38,\n",
       " 'making': 39,\n",
       " 'next': 40,\n",
       " 'word': 41,\n",
       " 'deep': 42,\n",
       " 'nlp': 43,\n",
       " 'natural': 44,\n",
       " 'processing': 45,\n",
       " 'keras': 46,\n",
       " 'pytorch': 47,\n",
       " 'tensorflow': 48,\n",
       " 'frameworks': 49,\n",
       " 'layers': 50,\n",
       " 'interests': 51,\n",
       " 'c': 52,\n",
       " 'google': 53,\n",
       " 'systems': 54,\n",
       " 'bit': 55,\n",
       " 'course': 56,\n",
       " 'on': 57,\n",
       " 'special': 58,\n",
       " 'saandhil': 59,\n",
       " 'agarwal': 60,\n",
       " 'bachelor': 61,\n",
       " 'b': 62,\n",
       " 'tech': 63,\n",
       " 'new': 64,\n",
       " 'look': 65,\n",
       " 'uchtar': 66,\n",
       " 'madhyamik': 67,\n",
       " 'vidyalaya': 68,\n",
       " 'kota': 69,\n",
       " 'central': 70,\n",
       " 'board': 71,\n",
       " 'secondary': 72,\n",
       " 'experience': 73,\n",
       " 'yhills': 74,\n",
       " 'campus': 75,\n",
       " 'ambassador': 76,\n",
       " 'organized': 77,\n",
       " 'managed': 78,\n",
       " 'group': 79,\n",
       " 'smooth': 80,\n",
       " 'enrollment': 81,\n",
       " 'courses': 82,\n",
       " 'addressed': 83,\n",
       " 'queries': 84,\n",
       " 'innovative': 85,\n",
       " 'strategies': 86,\n",
       " 'increased': 87,\n",
       " 'student': 88,\n",
       " 'engagement': 89,\n",
       " 'significantly': 90,\n",
       " 'personal': 91,\n",
       " 'projects': 92,\n",
       " 'ai': 93,\n",
       " 'powered': 94,\n",
       " 'recommender': 95,\n",
       " 'system': 96,\n",
       " 'applied': 97,\n",
       " 'engineering': 98,\n",
       " 'including': 99,\n",
       " 'transformation': 100,\n",
       " 'extraction': 101,\n",
       " 'one': 102,\n",
       " 'hot': 103,\n",
       " 'encoding': 104,\n",
       " 'profiling': 105,\n",
       " 'thorough': 106,\n",
       " 'utilized': 107,\n",
       " 'vectorization': 108,\n",
       " 'cosine': 109,\n",
       " 'similarities': 110,\n",
       " 'integrated': 111,\n",
       " 'apis': 112,\n",
       " 'streamlit’s': 113,\n",
       " 'interactive': 114,\n",
       " 'widgets': 115,\n",
       " 'effortless': 116,\n",
       " 'deployment': 117,\n",
       " 'recommendation': 118,\n",
       " 'vista': 119,\n",
       " 'dashboard': 120,\n",
       " 'refreshment': 121,\n",
       " 'drinks': 122,\n",
       " 'leveraged': 123,\n",
       " 'detailed': 124,\n",
       " 'american': 125,\n",
       " 'dynamic': 126,\n",
       " 'charts': 127,\n",
       " 'filters': 128,\n",
       " 'slices': 129,\n",
       " 'explored': 130,\n",
       " 'trends': 131,\n",
       " 'across': 132,\n",
       " 'states': 133,\n",
       " 'cities': 134,\n",
       " 'tool': 135,\n",
       " 'tips': 136,\n",
       " 'insights': 137,\n",
       " 'contributing': 138,\n",
       " 'strategic': 139,\n",
       " 'predictor': 140,\n",
       " 'llms': 141,\n",
       " 'developed': 142,\n",
       " 'llm': 143,\n",
       " 'predicting': 144,\n",
       " 'se': 145,\n",
       " 'quences': 146,\n",
       " 'modelling': 147,\n",
       " 'used': 148,\n",
       " 'implement': 149,\n",
       " 'incorporating': 150,\n",
       " 'embedding': 151,\n",
       " 'softmax': 152,\n",
       " 'achieve': 153,\n",
       " 'high': 154,\n",
       " 'accuracy': 155,\n",
       " 'through': 156,\n",
       " 'hyper': 157,\n",
       " 'parameter': 158,\n",
       " 'tuning': 159,\n",
       " 'technical': 160,\n",
       " 'skills': 161,\n",
       " 'languages': 162,\n",
       " 'libraries': 163,\n",
       " 'python': 164,\n",
       " 'numpy': 165,\n",
       " 'matplotlib': 166,\n",
       " 'scikit': 167,\n",
       " 'learn': 168,\n",
       " 'seaborn': 169,\n",
       " 'streamlit': 170,\n",
       " 'sql': 171,\n",
       " 'developer': 172,\n",
       " 'tools': 173,\n",
       " 'git': 174,\n",
       " 'github': 175,\n",
       " 'pycharm': 176,\n",
       " 'jupyter': 177,\n",
       " 'notebook': 178,\n",
       " 'colab': 179,\n",
       " 'vs': 180,\n",
       " 'code': 181,\n",
       " 'genai': 182,\n",
       " 'coursework': 183,\n",
       " '–': 184,\n",
       " 'image': 185,\n",
       " 'pattern': 186,\n",
       " 'recognition–': 187,\n",
       " 'processing–': 188,\n",
       " 'mining–': 189,\n",
       " 'operating': 190,\n",
       " 'base': 191,\n",
       " 'management': 192,\n",
       " 'positions': 193,\n",
       " 'responsibility': 194,\n",
       " 'event': 195,\n",
       " 'organizer': 196,\n",
       " 'sports': 197,\n",
       " 'adventure': 198,\n",
       " 'club': 199,\n",
       " 'senior': 200,\n",
       " 'executive': 201,\n",
       " 'dhwani': 202,\n",
       " 'certifications': 203,\n",
       " 'achievements': 204,\n",
       " 'accreditation': 205,\n",
       " 'showcasing': 206,\n",
       " 'proficiency': 207,\n",
       " 'visualization': 208,\n",
       " 'informed': 209,\n",
       " 'udemy’s': 210,\n",
       " 'accomplished': 211,\n",
       " '21': 212,\n",
       " 'days': 213,\n",
       " 'udemy': 214,\n",
       " 'applying': 215,\n",
       " 'algorithms': 216,\n",
       " 'real': 217,\n",
       " 'world': 218,\n",
       " 'datasets': 219,\n",
       " 'united': 220,\n",
       " 'nations': 221,\n",
       " 'recieved': 222,\n",
       " 'verbal': 223,\n",
       " 'unhrc': 224,\n",
       " 'committee': 225,\n",
       " '2': 226,\n",
       " 'consecutive': 227,\n",
       " 'years': 228}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4c3165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "572672de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saandhil Agarwal\n",
      " Bachelor of Technology\n",
      " Information Technology\n",
      " Birla Institute of Technology, Mesra\n",
      " \n",
      "Education\n",
      " Birla Institute of Technology, Mesra\n",
      " B.Tech in Information Technology\n",
      " New Look Uchtar Madhyamik Vidyalaya, Kota\n",
      " Central Board of Secondary Education\n",
      " \n",
      "Experience\n",
      " YHills\n",
      " Campus Ambassador\n",
      " Organized and managed with a group of students for the smooth enrollment of students in courses\n",
      " Addressed queries,implemented innovative strategies and increased student engagement significantly\n",
      " \n",
      "Personal Projects\n",
      " AI Powered Movie Recommender System (Machine Learning)\n",
      " Applied comprehensive feature engineering techniques including feature transformation, feature extraction and One Hot\n",
      " Encoding along with pandas profiling for thorough data analysis. Utilized text vectorization, cosine similarities and\n",
      " integrated APIs with streamlit’s interactive widgets with effortless deployment for movie recommendation\n",
      "Beverage Vista- A sales dashboard of refreshment drinks (Power BI)\n",
      " Leveraged Power BI for detailed analytics in American beverage sales along with dynamic charts using filters & slices.\n",
      " Explored trends across states and cities and implemented tool tips for insights contributing to strategic decision-making\n",
      " Next Word Predictor using LSTM and LLMs (Deep Learning, NLP)\n",
      " Developed a Natural Language Processing Model using LSTM & LLM techniques for predicting the next word in text se\n",
      "quences using language modelling. Used Keras, PyTorch and TensorFlow frameworks to implement the model incorporating\n",
      " embedding layers, LSTM and Softmax layers to achieve high accuracy through hyper-parameter tuning.\n",
      "\n",
      "\n",
      "Technical Skills and Interests\n",
      " Languages and Libraries: Python, C/C++, Numpy, Pandas, Matplotlib, Scikit-learn, Seaborn, Streamlit, SQL\n",
      " Developer Tools: Git/GitHub, Pycharm, Power BI, Jupyter Notebook, Google Colab, VS-Code\n",
      " Frameworks: Keras, TensorFlow, PyTorch\n",
      " Interests: Machine Learning, Deep Learning, NLP, GenAI\n",
      " Coursework:– Image Processing and Pattern Recognition– Natural Language Processing– Data Mining– Operating Systems and Data Base Management Systems\n",
      " \n",
      " Positions of Responsibility\n",
      " Event Organizer, Sports and Adventure Club, BIT Mesra\n",
      " Senior Executive, Dhwani, BIT Mesra\n",
      " \n",
      " Certifications and Achievements\n",
      " Google Analytics Accreditation\n",
      " Showcasing proficiency in data analysis and visualization for informed decision making\n",
      "Udemy’s Machine Learning Course\n",
      " Accomplished a comprehensive \"Machine Learning in 21 days\" course on Udemy applying algorithms on real world datasets\n",
      " Special Mention in Model United Nations\n",
      " Recieved a Special Mention and a Verbal Mention in the UNHRC Committee for 2 consecutive years\n"
     ]
    }
   ],
   "source": [
    "for sentence in faqs.split('\\n'):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df309db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 60]\n",
      "[61, 2, 7]\n",
      "[22, 7]\n",
      "[23, 24, 2, 7, 9]\n",
      "[]\n",
      "[25]\n",
      "[23, 24, 2, 7, 9]\n",
      "[62, 63, 3, 22, 7]\n",
      "[64, 65, 66, 67, 68, 69]\n",
      "[70, 71, 2, 72, 25]\n",
      "[]\n",
      "[73]\n",
      "[74]\n",
      "[75, 76]\n",
      "[77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80, 81, 2, 26, 3, 82]\n",
      "[83, 84, 27, 85, 86, 1, 87, 88, 89, 90]\n",
      "[]\n",
      "[91, 92]\n",
      "[93, 94, 28, 95, 96, 11, 6]\n",
      "[97, 29, 14, 98, 30, 99, 14, 100, 14, 101, 1, 102, 103]\n",
      "[104, 31, 8, 32, 105, 4, 106, 12, 33, 107, 34, 108, 109, 110, 1]\n",
      "[111, 112, 8, 113, 114, 115, 8, 116, 117, 4, 28, 118]\n",
      "[35, 119, 5, 36, 120, 2, 121, 122, 15, 16]\n",
      "[123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8, 126, 127, 13, 128, 129]\n",
      "[130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137, 138, 17, 139, 38, 39]\n",
      "[40, 41, 140, 13, 18, 1, 141, 42, 6, 43]\n",
      "[142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10, 40, 41, 3, 34, 145]\n",
      "[146, 13, 19, 147, 148, 46, 47, 1, 48, 49, 17, 149, 10, 20, 150]\n",
      "[151, 50, 18, 1, 152, 50, 17, 153, 154, 155, 156, 157, 158, 159]\n",
      "[]\n",
      "[]\n",
      "[160, 161, 1, 51]\n",
      "[162, 1, 163, 164, 52, 52, 165, 32, 166, 167, 168, 169, 170, 171]\n",
      "[172, 173, 174, 175, 176, 15, 16, 177, 178, 53, 179, 180, 181]\n",
      "[49, 46, 48, 47]\n",
      "[51, 11, 6, 42, 6, 43, 182]\n",
      "[183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189, 190, 54, 1, 12, 191, 192, 54]\n",
      "[]\n",
      "[193, 2, 194]\n",
      "[195, 196, 197, 1, 198, 199, 55, 9]\n",
      "[200, 201, 202, 55, 9]\n",
      "[]\n",
      "[203, 1, 204]\n",
      "[53, 37, 205]\n",
      "[206, 207, 3, 12, 33, 1, 208, 4, 209, 38, 39]\n",
      "[210, 11, 6, 56]\n",
      "[211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215, 216, 57, 217, 218, 219]\n",
      "[58, 21, 3, 20, 220, 221]\n",
      "[222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224, 225, 4, 226, 227, 228]\n"
     ]
    }
   ],
   "source": [
    "for sentence in faqs.split('\\n'):\n",
    "    print(tokenizer.texts_to_sequences([sentence])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5134bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for sentence in faqs.split('\\n'):\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    for i in range(1, len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d4a9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[59, 60],\n",
       " [61, 2],\n",
       " [61, 2, 7],\n",
       " [22, 7],\n",
       " [23, 24],\n",
       " [23, 24, 2],\n",
       " [23, 24, 2, 7],\n",
       " [23, 24, 2, 7, 9],\n",
       " [23, 24],\n",
       " [23, 24, 2],\n",
       " [23, 24, 2, 7],\n",
       " [23, 24, 2, 7, 9],\n",
       " [62, 63],\n",
       " [62, 63, 3],\n",
       " [62, 63, 3, 22],\n",
       " [62, 63, 3, 22, 7],\n",
       " [64, 65],\n",
       " [64, 65, 66],\n",
       " [64, 65, 66, 67],\n",
       " [64, 65, 66, 67, 68],\n",
       " [64, 65, 66, 67, 68, 69],\n",
       " [70, 71],\n",
       " [70, 71, 2],\n",
       " [70, 71, 2, 72],\n",
       " [70, 71, 2, 72, 25],\n",
       " [75, 76],\n",
       " [77, 1],\n",
       " [77, 1, 78],\n",
       " [77, 1, 78, 8],\n",
       " [77, 1, 78, 8, 5],\n",
       " [77, 1, 78, 8, 5, 79],\n",
       " [77, 1, 78, 8, 5, 79, 2],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80, 81],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80, 81, 2],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80, 81, 2, 26],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80, 81, 2, 26, 3],\n",
       " [77, 1, 78, 8, 5, 79, 2, 26, 4, 10, 80, 81, 2, 26, 3, 82],\n",
       " [83, 84],\n",
       " [83, 84, 27],\n",
       " [83, 84, 27, 85],\n",
       " [83, 84, 27, 85, 86],\n",
       " [83, 84, 27, 85, 86, 1],\n",
       " [83, 84, 27, 85, 86, 1, 87],\n",
       " [83, 84, 27, 85, 86, 1, 87, 88],\n",
       " [83, 84, 27, 85, 86, 1, 87, 88, 89],\n",
       " [83, 84, 27, 85, 86, 1, 87, 88, 89, 90],\n",
       " [91, 92],\n",
       " [93, 94],\n",
       " [93, 94, 28],\n",
       " [93, 94, 28, 95],\n",
       " [93, 94, 28, 95, 96],\n",
       " [93, 94, 28, 95, 96, 11],\n",
       " [93, 94, 28, 95, 96, 11, 6],\n",
       " [97, 29],\n",
       " [97, 29, 14],\n",
       " [97, 29, 14, 98],\n",
       " [97, 29, 14, 98, 30],\n",
       " [97, 29, 14, 98, 30, 99],\n",
       " [97, 29, 14, 98, 30, 99, 14],\n",
       " [97, 29, 14, 98, 30, 99, 14, 100],\n",
       " [97, 29, 14, 98, 30, 99, 14, 100, 14],\n",
       " [97, 29, 14, 98, 30, 99, 14, 100, 14, 101],\n",
       " [97, 29, 14, 98, 30, 99, 14, 100, 14, 101, 1],\n",
       " [97, 29, 14, 98, 30, 99, 14, 100, 14, 101, 1, 102],\n",
       " [97, 29, 14, 98, 30, 99, 14, 100, 14, 101, 1, 102, 103],\n",
       " [104, 31],\n",
       " [104, 31, 8],\n",
       " [104, 31, 8, 32],\n",
       " [104, 31, 8, 32, 105],\n",
       " [104, 31, 8, 32, 105, 4],\n",
       " [104, 31, 8, 32, 105, 4, 106],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33, 107],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33, 107, 34],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33, 107, 34, 108],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33, 107, 34, 108, 109],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33, 107, 34, 108, 109, 110],\n",
       " [104, 31, 8, 32, 105, 4, 106, 12, 33, 107, 34, 108, 109, 110, 1],\n",
       " [111, 112],\n",
       " [111, 112, 8],\n",
       " [111, 112, 8, 113],\n",
       " [111, 112, 8, 113, 114],\n",
       " [111, 112, 8, 113, 114, 115],\n",
       " [111, 112, 8, 113, 114, 115, 8],\n",
       " [111, 112, 8, 113, 114, 115, 8, 116],\n",
       " [111, 112, 8, 113, 114, 115, 8, 116, 117],\n",
       " [111, 112, 8, 113, 114, 115, 8, 116, 117, 4],\n",
       " [111, 112, 8, 113, 114, 115, 8, 116, 117, 4, 28],\n",
       " [111, 112, 8, 113, 114, 115, 8, 116, 117, 4, 28, 118],\n",
       " [35, 119],\n",
       " [35, 119, 5],\n",
       " [35, 119, 5, 36],\n",
       " [35, 119, 5, 36, 120],\n",
       " [35, 119, 5, 36, 120, 2],\n",
       " [35, 119, 5, 36, 120, 2, 121],\n",
       " [35, 119, 5, 36, 120, 2, 121, 122],\n",
       " [35, 119, 5, 36, 120, 2, 121, 122, 15],\n",
       " [35, 119, 5, 36, 120, 2, 121, 122, 15, 16],\n",
       " [123, 15],\n",
       " [123, 15, 16],\n",
       " [123, 15, 16, 4],\n",
       " [123, 15, 16, 4, 124],\n",
       " [123, 15, 16, 4, 124, 37],\n",
       " [123, 15, 16, 4, 124, 37, 3],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8, 126],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8, 126, 127],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8, 126, 127, 13],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8, 126, 127, 13, 128],\n",
       " [123, 15, 16, 4, 124, 37, 3, 125, 35, 36, 31, 8, 126, 127, 13, 128, 129],\n",
       " [130, 131],\n",
       " [130, 131, 132],\n",
       " [130, 131, 132, 133],\n",
       " [130, 131, 132, 133, 1],\n",
       " [130, 131, 132, 133, 1, 134],\n",
       " [130, 131, 132, 133, 1, 134, 1],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137, 138],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137, 138, 17],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137, 138, 17, 139],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137, 138, 17, 139, 38],\n",
       " [130, 131, 132, 133, 1, 134, 1, 27, 135, 136, 4, 137, 138, 17, 139, 38, 39],\n",
       " [40, 41],\n",
       " [40, 41, 140],\n",
       " [40, 41, 140, 13],\n",
       " [40, 41, 140, 13, 18],\n",
       " [40, 41, 140, 13, 18, 1],\n",
       " [40, 41, 140, 13, 18, 1, 141],\n",
       " [40, 41, 140, 13, 18, 1, 141, 42],\n",
       " [40, 41, 140, 13, 18, 1, 141, 42, 6],\n",
       " [40, 41, 140, 13, 18, 1, 141, 42, 6, 43],\n",
       " [142, 5],\n",
       " [142, 5, 44],\n",
       " [142, 5, 44, 19],\n",
       " [142, 5, 44, 19, 45],\n",
       " [142, 5, 44, 19, 45, 20],\n",
       " [142, 5, 44, 19, 45, 20, 13],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10, 40],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10, 40, 41],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10, 40, 41, 3],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10, 40, 41, 3, 34],\n",
       " [142, 5, 44, 19, 45, 20, 13, 18, 143, 30, 4, 144, 10, 40, 41, 3, 34, 145],\n",
       " [146, 13],\n",
       " [146, 13, 19],\n",
       " [146, 13, 19, 147],\n",
       " [146, 13, 19, 147, 148],\n",
       " [146, 13, 19, 147, 148, 46],\n",
       " [146, 13, 19, 147, 148, 46, 47],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48, 49],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48, 49, 17],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48, 49, 17, 149],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48, 49, 17, 149, 10],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48, 49, 17, 149, 10, 20],\n",
       " [146, 13, 19, 147, 148, 46, 47, 1, 48, 49, 17, 149, 10, 20, 150],\n",
       " [151, 50],\n",
       " [151, 50, 18],\n",
       " [151, 50, 18, 1],\n",
       " [151, 50, 18, 1, 152],\n",
       " [151, 50, 18, 1, 152, 50],\n",
       " [151, 50, 18, 1, 152, 50, 17],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153, 154],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153, 154, 155],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153, 154, 155, 156],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153, 154, 155, 156, 157],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153, 154, 155, 156, 157, 158],\n",
       " [151, 50, 18, 1, 152, 50, 17, 153, 154, 155, 156, 157, 158, 159],\n",
       " [160, 161],\n",
       " [160, 161, 1],\n",
       " [160, 161, 1, 51],\n",
       " [162, 1],\n",
       " [162, 1, 163],\n",
       " [162, 1, 163, 164],\n",
       " [162, 1, 163, 164, 52],\n",
       " [162, 1, 163, 164, 52, 52],\n",
       " [162, 1, 163, 164, 52, 52, 165],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32, 166],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32, 166, 167],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32, 166, 167, 168],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32, 166, 167, 168, 169],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32, 166, 167, 168, 169, 170],\n",
       " [162, 1, 163, 164, 52, 52, 165, 32, 166, 167, 168, 169, 170, 171],\n",
       " [172, 173],\n",
       " [172, 173, 174],\n",
       " [172, 173, 174, 175],\n",
       " [172, 173, 174, 175, 176],\n",
       " [172, 173, 174, 175, 176, 15],\n",
       " [172, 173, 174, 175, 176, 15, 16],\n",
       " [172, 173, 174, 175, 176, 15, 16, 177],\n",
       " [172, 173, 174, 175, 176, 15, 16, 177, 178],\n",
       " [172, 173, 174, 175, 176, 15, 16, 177, 178, 53],\n",
       " [172, 173, 174, 175, 176, 15, 16, 177, 178, 53, 179],\n",
       " [172, 173, 174, 175, 176, 15, 16, 177, 178, 53, 179, 180],\n",
       " [172, 173, 174, 175, 176, 15, 16, 177, 178, 53, 179, 180, 181],\n",
       " [49, 46],\n",
       " [49, 46, 48],\n",
       " [49, 46, 48, 47],\n",
       " [51, 11],\n",
       " [51, 11, 6],\n",
       " [51, 11, 6, 42],\n",
       " [51, 11, 6, 42, 6],\n",
       " [51, 11, 6, 42, 6, 43],\n",
       " [51, 11, 6, 42, 6, 43, 182],\n",
       " [183, 184],\n",
       " [183, 184, 185],\n",
       " [183, 184, 185, 45],\n",
       " [183, 184, 185, 45, 1],\n",
       " [183, 184, 185, 45, 1, 186],\n",
       " [183, 184, 185, 45, 1, 186, 187],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189, 190],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189, 190, 54],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189, 190, 54, 1],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189, 190, 54, 1, 12],\n",
       " [183, 184, 185, 45, 1, 186, 187, 44, 19, 188, 12, 189, 190, 54, 1, 12, 191],\n",
       " [183,\n",
       "  184,\n",
       "  185,\n",
       "  45,\n",
       "  1,\n",
       "  186,\n",
       "  187,\n",
       "  44,\n",
       "  19,\n",
       "  188,\n",
       "  12,\n",
       "  189,\n",
       "  190,\n",
       "  54,\n",
       "  1,\n",
       "  12,\n",
       "  191,\n",
       "  192],\n",
       " [183,\n",
       "  184,\n",
       "  185,\n",
       "  45,\n",
       "  1,\n",
       "  186,\n",
       "  187,\n",
       "  44,\n",
       "  19,\n",
       "  188,\n",
       "  12,\n",
       "  189,\n",
       "  190,\n",
       "  54,\n",
       "  1,\n",
       "  12,\n",
       "  191,\n",
       "  192,\n",
       "  54],\n",
       " [193, 2],\n",
       " [193, 2, 194],\n",
       " [195, 196],\n",
       " [195, 196, 197],\n",
       " [195, 196, 197, 1],\n",
       " [195, 196, 197, 1, 198],\n",
       " [195, 196, 197, 1, 198, 199],\n",
       " [195, 196, 197, 1, 198, 199, 55],\n",
       " [195, 196, 197, 1, 198, 199, 55, 9],\n",
       " [200, 201],\n",
       " [200, 201, 202],\n",
       " [200, 201, 202, 55],\n",
       " [200, 201, 202, 55, 9],\n",
       " [203, 1],\n",
       " [203, 1, 204],\n",
       " [53, 37],\n",
       " [53, 37, 205],\n",
       " [206, 207],\n",
       " [206, 207, 3],\n",
       " [206, 207, 3, 12],\n",
       " [206, 207, 3, 12, 33],\n",
       " [206, 207, 3, 12, 33, 1],\n",
       " [206, 207, 3, 12, 33, 1, 208],\n",
       " [206, 207, 3, 12, 33, 1, 208, 4],\n",
       " [206, 207, 3, 12, 33, 1, 208, 4, 209],\n",
       " [206, 207, 3, 12, 33, 1, 208, 4, 209, 38],\n",
       " [206, 207, 3, 12, 33, 1, 208, 4, 209, 38, 39],\n",
       " [210, 11],\n",
       " [210, 11, 6],\n",
       " [210, 11, 6, 56],\n",
       " [211, 5],\n",
       " [211, 5, 29],\n",
       " [211, 5, 29, 11],\n",
       " [211, 5, 29, 11, 6],\n",
       " [211, 5, 29, 11, 6, 3],\n",
       " [211, 5, 29, 11, 6, 3, 212],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215, 216],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215, 216, 57],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215, 216, 57, 217],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215, 216, 57, 217, 218],\n",
       " [211, 5, 29, 11, 6, 3, 212, 213, 56, 57, 214, 215, 216, 57, 217, 218, 219],\n",
       " [58, 21],\n",
       " [58, 21, 3],\n",
       " [58, 21, 3, 20],\n",
       " [58, 21, 3, 20, 220],\n",
       " [58, 21, 3, 20, 220, 221],\n",
       " [222, 5],\n",
       " [222, 5, 58],\n",
       " [222, 5, 58, 21],\n",
       " [222, 5, 58, 21, 1],\n",
       " [222, 5, 58, 21, 1, 5],\n",
       " [222, 5, 58, 21, 1, 5, 223],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224, 225],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224, 225, 4],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224, 225, 4, 226],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224, 225, 4, 226, 227],\n",
       " [222, 5, 58, 21, 1, 5, 223, 21, 3, 10, 224, 225, 4, 226, 227, 228]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c7e1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "450735c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "502ce096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences=pad_sequences(input_sequences, maxlen =max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdf29e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  59,  60],\n",
       "       [  0,   0,   0, ...,   0,  61,   2],\n",
       "       [  0,   0,   0, ...,  61,   2,   7],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 225,   4, 226],\n",
       "       [  0,   0,   0, ...,   4, 226, 227],\n",
       "       [  0,   0,   0, ..., 226, 227, 228]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9746cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=padded_input_sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a46bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0d7c186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e160a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7863ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y=to_categorical(y,num_classes=229)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6038ae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 229)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "565a64fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65bdb255",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(229,100,input_length=18))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(229,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81f800ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0220ed2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 18, 100)           22900     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 150)               150600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 229)               34579     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 208079 (812.81 KB)\n",
      "Trainable params: 208079 (812.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab38b44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,  59],\n",
       "       [  0,   0,   0, ...,   0,   0,  61],\n",
       "       [  0,   0,   0, ...,   0,  61,   2],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 224, 225,   4],\n",
       "       [  0,   0,   0, ..., 225,   4, 226],\n",
       "       [  0,   0,   0, ...,   4, 226, 227]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60dadb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 4s 29ms/step - loss: 5.4316 - accuracy: 0.0097\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 5.3537 - accuracy: 0.0550\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 5.1748 - accuracy: 0.0550\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 5.0588 - accuracy: 0.0550\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 5.0047 - accuracy: 0.0583\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 4.9545 - accuracy: 0.0550\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 4.9111 - accuracy: 0.0615\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 4.8389 - accuracy: 0.0550\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 4.7702 - accuracy: 0.0647\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 4.6798 - accuracy: 0.0680\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 4.5733 - accuracy: 0.0615\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 4.4708 - accuracy: 0.0680\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 4.4132 - accuracy: 0.0680\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 4.3225 - accuracy: 0.0777\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 4.2635 - accuracy: 0.0939\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 4.1249 - accuracy: 0.1068\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 3.9839 - accuracy: 0.1489\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 3.8747 - accuracy: 0.1521\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 3.7508 - accuracy: 0.1748\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 3.6287 - accuracy: 0.2006\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 3.4917 - accuracy: 0.2136\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 3.3574 - accuracy: 0.2492\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 3.2297 - accuracy: 0.2751\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 3.1131 - accuracy: 0.3107\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 3.0146 - accuracy: 0.3430\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 2.8852 - accuracy: 0.3269\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2.7607 - accuracy: 0.4110\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2.6320 - accuracy: 0.4142\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2.5354 - accuracy: 0.4434\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 2.4401 - accuracy: 0.4466\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2.3366 - accuracy: 0.4725\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 2.2399 - accuracy: 0.4951\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2.1524 - accuracy: 0.5340\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2.0404 - accuracy: 0.5663\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 1.9698 - accuracy: 0.5696\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 1.8952 - accuracy: 0.5890\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1.8184 - accuracy: 0.5987\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 1.7716 - accuracy: 0.6019\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.7099 - accuracy: 0.6408\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 1.6776 - accuracy: 0.6214\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1.6084 - accuracy: 0.6634\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.4986 - accuracy: 0.7379\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.4404 - accuracy: 0.7735\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.3767 - accuracy: 0.7670\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.3132 - accuracy: 0.7994\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.2537 - accuracy: 0.8317\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1.1969 - accuracy: 0.8511\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.1450 - accuracy: 0.8576\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.0958 - accuracy: 0.8706\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.0476 - accuracy: 0.8738\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.9993 - accuracy: 0.9094\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.9639 - accuracy: 0.9126\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.9260 - accuracy: 0.9061\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.8816 - accuracy: 0.9191\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.8486 - accuracy: 0.9417\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.8086 - accuracy: 0.9482\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.7753 - accuracy: 0.9515\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.7429 - accuracy: 0.9579\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.7104 - accuracy: 0.9612\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6800 - accuracy: 0.9644\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6522 - accuracy: 0.9676\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6260 - accuracy: 0.9644\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.5960 - accuracy: 0.9806\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.5741 - accuracy: 0.9806\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5545 - accuracy: 0.9806\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5290 - accuracy: 0.9806\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5100 - accuracy: 0.9935\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4942 - accuracy: 0.9903\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4694 - accuracy: 0.9968\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.4453 - accuracy: 0.9935\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.4435 - accuracy: 0.9935\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.4218 - accuracy: 0.9968\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.4013 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3890 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.3690 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.3737 - accuracy: 0.9935\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.3853 - accuracy: 0.9838\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.4176 - accuracy: 0.9709\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3561 - accuracy: 0.9903\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3377 - accuracy: 0.9903\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3027 - accuracy: 1.0000\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 24ms/step - loss: 0.2944 - accuracy: 0.9968\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.2783 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2620 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.2481 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.2391 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.2306 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2222 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.2161 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2101 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2013 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.1952 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.1899 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.1835 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.1764 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1706 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.1657 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.1609 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.1562 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.1522 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23703a143d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e41b03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Birla\"\n",
    "#tokenize\n",
    "token_text=tokenizer.texts_to_sequences([text])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b608eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23]]\n"
     ]
    }
   ],
   "source": [
    "#padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_text=pad_sequences([token_text],maxlen=18,padding='pre')\n",
    "print(padded_input_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e078249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 814ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.3093413e-07, 1.4657463e-04, 1.4575416e-02, 3.0930622e-03,\n",
       "        1.7408807e-04, 7.3240785e-04, 5.3618578e-07, 3.5909433e-03,\n",
       "        4.5367829e-05, 2.7589782e-03, 2.4643301e-05, 3.1868483e-05,\n",
       "        1.1336648e-05, 3.9393388e-04, 4.1610347e-05, 8.7704015e-04,\n",
       "        1.0232070e-04, 9.1249154e-07, 2.3706532e-05, 4.2300413e-05,\n",
       "        9.2346534e-05, 2.5052610e-03, 3.8138966e-04, 3.0285511e-07,\n",
       "        9.1732812e-01, 1.9437372e-05, 6.0823550e-05, 2.0782456e-07,\n",
       "        7.6499207e-05, 6.3004598e-05, 7.9173624e-05, 5.2060053e-04,\n",
       "        2.0000938e-05, 7.9338661e-06, 6.8169861e-06, 1.6783888e-05,\n",
       "        5.5843877e-04, 8.0936011e-03, 1.7225376e-06, 1.9841077e-06,\n",
       "        6.1017367e-05, 3.9002360e-03, 2.1242031e-05, 2.3912547e-05,\n",
       "        6.5142536e-05, 5.1550983e-06, 1.6852946e-04, 2.2358008e-05,\n",
       "        5.1880019e-05, 2.2297227e-06, 2.1613687e-06, 3.3839973e-07,\n",
       "        1.0870097e-06, 1.2659730e-06, 9.0262142e-07, 1.8935694e-05,\n",
       "        6.6961125e-05, 1.2188992e-05, 1.2319043e-04, 3.7747472e-07,\n",
       "        3.4262700e-04, 1.9477989e-07, 1.3846292e-07, 1.7487064e-02,\n",
       "        1.9535770e-07, 1.5651603e-05, 1.8957875e-06, 1.1840764e-07,\n",
       "        7.3152705e-07, 1.5700054e-05, 1.5026096e-07, 4.5187683e-03,\n",
       "        1.2246687e-04, 3.0528923e-07, 2.8566481e-07, 5.6561413e-07,\n",
       "        2.6220889e-04, 1.5297739e-07, 1.2552571e-05, 2.0197909e-05,\n",
       "        3.3178585e-05, 1.3248203e-04, 7.0157089e-06, 2.9549207e-07,\n",
       "        3.9384522e-06, 5.5180532e-08, 1.7669745e-07, 9.3699953e-08,\n",
       "        2.0178040e-07, 3.1915414e-07, 6.2611900e-07, 3.0360988e-07,\n",
       "        8.4786239e-05, 2.9544532e-07, 2.5105357e-04, 2.2313041e-05,\n",
       "        2.8889038e-04, 2.3236613e-07, 3.2699243e-06, 1.4632105e-05,\n",
       "        6.7823453e-06, 9.1622860e-06, 2.3555865e-06, 5.6310423e-06,\n",
       "        4.5730278e-07, 4.4534590e-06, 2.8532639e-05, 6.8291347e-06,\n",
       "        9.3025683e-06, 6.7818860e-06, 4.0132022e-06, 2.7352385e-07,\n",
       "        7.7671299e-05, 5.5572946e-05, 4.9689552e-06, 4.6125688e-06,\n",
       "        2.8838908e-06, 6.9424027e-06, 1.6960958e-06, 3.0609637e-03,\n",
       "        3.8510046e-04, 4.5098481e-05, 1.1590280e-05, 2.5946699e-07,\n",
       "        1.6987216e-04, 1.2094356e-05, 6.5930999e-06, 4.9370595e-07,\n",
       "        6.1016601e-07, 4.0802061e-07, 2.1052735e-07, 1.7359453e-04,\n",
       "        1.2832422e-04, 4.8852148e-06, 1.5543053e-06, 1.2592065e-07,\n",
       "        1.0746069e-06, 1.5553729e-06, 1.1547467e-06, 6.8890165e-07,\n",
       "        2.1377530e-04, 6.0407223e-07, 2.0263118e-07, 1.7157705e-05,\n",
       "        1.6463027e-05, 4.7582112e-06, 1.3633147e-07, 7.4027725e-05,\n",
       "        2.5213737e-04, 2.5953248e-06, 1.6886095e-05, 3.4968218e-07,\n",
       "        2.9998202e-07, 5.8451053e-07, 3.9324973e-07, 7.7896505e-07,\n",
       "        1.2837617e-07, 3.0124343e-07, 8.9870633e-07, 1.6169726e-06,\n",
       "        3.6998807e-07, 2.4739645e-06, 4.8393338e-07, 2.8406143e-07,\n",
       "        6.8255827e-07, 6.6804915e-07, 3.7897814e-07, 7.5600025e-07,\n",
       "        2.2404858e-07, 1.1047637e-06, 3.6244521e-07, 9.2420215e-08,\n",
       "        9.9436498e-08, 7.4471769e-05, 3.3422133e-05, 3.0051046e-06,\n",
       "        2.2081022e-06, 1.9332385e-05, 4.7216645e-06, 6.3321108e-06,\n",
       "        2.9210037e-06, 1.4509940e-06, 6.7708093e-06, 1.4479355e-07,\n",
       "        3.3757606e-04, 1.2249238e-05, 2.4836368e-07, 5.9635624e-07,\n",
       "        3.8007288e-06, 3.0747760e-06, 4.0400364e-06, 4.9161804e-07,\n",
       "        2.8214345e-07, 1.3052197e-07, 1.2474733e-04, 2.1474946e-07,\n",
       "        8.6082183e-03, 2.8805019e-04, 2.3641790e-06, 4.4416403e-05,\n",
       "        1.9848581e-07, 1.5217790e-04, 1.8107499e-05, 2.0638707e-07,\n",
       "        5.7071014e-07, 3.1131427e-04, 5.9012615e-07, 3.7182996e-05,\n",
       "        1.2128203e-06, 1.0828013e-05, 1.9565918e-07, 2.8545182e-07,\n",
       "        4.2430042e-06, 8.9273235e-06, 1.6890386e-06, 2.0080015e-06,\n",
       "        1.1767149e-06, 5.4060604e-07, 5.9185503e-08, 2.6333430e-08,\n",
       "        2.3254049e-04, 1.3161594e-05, 2.6101145e-07, 1.2297040e-05,\n",
       "        2.9014123e-05, 3.3922288e-06, 1.1819216e-05, 3.3891956e-06,\n",
       "        2.9039049e-06]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "model.predict(padded_input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d43b29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 229)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_input_text).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef0b9096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(model.predict(padded_input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "634fd766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 1,\n",
       " 'of': 2,\n",
       " 'in': 3,\n",
       " 'for': 4,\n",
       " 'a': 5,\n",
       " 'learning': 6,\n",
       " 'technology': 7,\n",
       " 'with': 8,\n",
       " 'mesra': 9,\n",
       " 'the': 10,\n",
       " 'machine': 11,\n",
       " 'data': 12,\n",
       " 'using': 13,\n",
       " 'feature': 14,\n",
       " 'power': 15,\n",
       " 'bi': 16,\n",
       " 'to': 17,\n",
       " 'lstm': 18,\n",
       " 'language': 19,\n",
       " 'model': 20,\n",
       " 'mention': 21,\n",
       " 'information': 22,\n",
       " 'birla': 23,\n",
       " 'institute': 24,\n",
       " 'education': 25,\n",
       " 'students': 26,\n",
       " 'implemented': 27,\n",
       " 'movie': 28,\n",
       " 'comprehensive': 29,\n",
       " 'techniques': 30,\n",
       " 'along': 31,\n",
       " 'pandas': 32,\n",
       " 'analysis': 33,\n",
       " 'text': 34,\n",
       " 'beverage': 35,\n",
       " 'sales': 36,\n",
       " 'analytics': 37,\n",
       " 'decision': 38,\n",
       " 'making': 39,\n",
       " 'next': 40,\n",
       " 'word': 41,\n",
       " 'deep': 42,\n",
       " 'nlp': 43,\n",
       " 'natural': 44,\n",
       " 'processing': 45,\n",
       " 'keras': 46,\n",
       " 'pytorch': 47,\n",
       " 'tensorflow': 48,\n",
       " 'frameworks': 49,\n",
       " 'layers': 50,\n",
       " 'interests': 51,\n",
       " 'c': 52,\n",
       " 'google': 53,\n",
       " 'systems': 54,\n",
       " 'bit': 55,\n",
       " 'course': 56,\n",
       " 'on': 57,\n",
       " 'special': 58,\n",
       " 'saandhil': 59,\n",
       " 'agarwal': 60,\n",
       " 'bachelor': 61,\n",
       " 'b': 62,\n",
       " 'tech': 63,\n",
       " 'new': 64,\n",
       " 'look': 65,\n",
       " 'uchtar': 66,\n",
       " 'madhyamik': 67,\n",
       " 'vidyalaya': 68,\n",
       " 'kota': 69,\n",
       " 'central': 70,\n",
       " 'board': 71,\n",
       " 'secondary': 72,\n",
       " 'experience': 73,\n",
       " 'yhills': 74,\n",
       " 'campus': 75,\n",
       " 'ambassador': 76,\n",
       " 'organized': 77,\n",
       " 'managed': 78,\n",
       " 'group': 79,\n",
       " 'smooth': 80,\n",
       " 'enrollment': 81,\n",
       " 'courses': 82,\n",
       " 'addressed': 83,\n",
       " 'queries': 84,\n",
       " 'innovative': 85,\n",
       " 'strategies': 86,\n",
       " 'increased': 87,\n",
       " 'student': 88,\n",
       " 'engagement': 89,\n",
       " 'significantly': 90,\n",
       " 'personal': 91,\n",
       " 'projects': 92,\n",
       " 'ai': 93,\n",
       " 'powered': 94,\n",
       " 'recommender': 95,\n",
       " 'system': 96,\n",
       " 'applied': 97,\n",
       " 'engineering': 98,\n",
       " 'including': 99,\n",
       " 'transformation': 100,\n",
       " 'extraction': 101,\n",
       " 'one': 102,\n",
       " 'hot': 103,\n",
       " 'encoding': 104,\n",
       " 'profiling': 105,\n",
       " 'thorough': 106,\n",
       " 'utilized': 107,\n",
       " 'vectorization': 108,\n",
       " 'cosine': 109,\n",
       " 'similarities': 110,\n",
       " 'integrated': 111,\n",
       " 'apis': 112,\n",
       " 'streamlit’s': 113,\n",
       " 'interactive': 114,\n",
       " 'widgets': 115,\n",
       " 'effortless': 116,\n",
       " 'deployment': 117,\n",
       " 'recommendation': 118,\n",
       " 'vista': 119,\n",
       " 'dashboard': 120,\n",
       " 'refreshment': 121,\n",
       " 'drinks': 122,\n",
       " 'leveraged': 123,\n",
       " 'detailed': 124,\n",
       " 'american': 125,\n",
       " 'dynamic': 126,\n",
       " 'charts': 127,\n",
       " 'filters': 128,\n",
       " 'slices': 129,\n",
       " 'explored': 130,\n",
       " 'trends': 131,\n",
       " 'across': 132,\n",
       " 'states': 133,\n",
       " 'cities': 134,\n",
       " 'tool': 135,\n",
       " 'tips': 136,\n",
       " 'insights': 137,\n",
       " 'contributing': 138,\n",
       " 'strategic': 139,\n",
       " 'predictor': 140,\n",
       " 'llms': 141,\n",
       " 'developed': 142,\n",
       " 'llm': 143,\n",
       " 'predicting': 144,\n",
       " 'se': 145,\n",
       " 'quences': 146,\n",
       " 'modelling': 147,\n",
       " 'used': 148,\n",
       " 'implement': 149,\n",
       " 'incorporating': 150,\n",
       " 'embedding': 151,\n",
       " 'softmax': 152,\n",
       " 'achieve': 153,\n",
       " 'high': 154,\n",
       " 'accuracy': 155,\n",
       " 'through': 156,\n",
       " 'hyper': 157,\n",
       " 'parameter': 158,\n",
       " 'tuning': 159,\n",
       " 'technical': 160,\n",
       " 'skills': 161,\n",
       " 'languages': 162,\n",
       " 'libraries': 163,\n",
       " 'python': 164,\n",
       " 'numpy': 165,\n",
       " 'matplotlib': 166,\n",
       " 'scikit': 167,\n",
       " 'learn': 168,\n",
       " 'seaborn': 169,\n",
       " 'streamlit': 170,\n",
       " 'sql': 171,\n",
       " 'developer': 172,\n",
       " 'tools': 173,\n",
       " 'git': 174,\n",
       " 'github': 175,\n",
       " 'pycharm': 176,\n",
       " 'jupyter': 177,\n",
       " 'notebook': 178,\n",
       " 'colab': 179,\n",
       " 'vs': 180,\n",
       " 'code': 181,\n",
       " 'genai': 182,\n",
       " 'coursework': 183,\n",
       " '–': 184,\n",
       " 'image': 185,\n",
       " 'pattern': 186,\n",
       " 'recognition–': 187,\n",
       " 'processing–': 188,\n",
       " 'mining–': 189,\n",
       " 'operating': 190,\n",
       " 'base': 191,\n",
       " 'management': 192,\n",
       " 'positions': 193,\n",
       " 'responsibility': 194,\n",
       " 'event': 195,\n",
       " 'organizer': 196,\n",
       " 'sports': 197,\n",
       " 'adventure': 198,\n",
       " 'club': 199,\n",
       " 'senior': 200,\n",
       " 'executive': 201,\n",
       " 'dhwani': 202,\n",
       " 'certifications': 203,\n",
       " 'achievements': 204,\n",
       " 'accreditation': 205,\n",
       " 'showcasing': 206,\n",
       " 'proficiency': 207,\n",
       " 'visualization': 208,\n",
       " 'informed': 209,\n",
       " 'udemy’s': 210,\n",
       " 'accomplished': 211,\n",
       " '21': 212,\n",
       " 'days': 213,\n",
       " 'udemy': 214,\n",
       " 'applying': 215,\n",
       " 'algorithms': 216,\n",
       " 'real': 217,\n",
       " 'world': 218,\n",
       " 'datasets': 219,\n",
       " 'united': 220,\n",
       " 'nations': 221,\n",
       " 'recieved': 222,\n",
       " 'verbal': 223,\n",
       " 'unhrc': 224,\n",
       " 'committee': 225,\n",
       " '2': 226,\n",
       " 'consecutive': 227,\n",
       " 'years': 228}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ec09b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "institute\n"
     ]
    }
   ],
   "source": [
    "pos=np.argmax(model.predict(padded_input_text))\n",
    "for word,index in tokenizer.word_index.items():\n",
    "  if index==pos:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3a57624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "mail –\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "mail – –\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "mail – – image\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "mail – – image processing\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "mail – – image processing and\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text=\"mail\"\n",
    " \n",
    "for i in range(5):\n",
    "    #tokenize\n",
    "    token_text=tokenizer.texts_to_sequences([text])[0]\n",
    "    #padding\n",
    "    padded_input_text=pad_sequences([token_text],maxlen=18,padding='pre')\n",
    "    #predict\n",
    "    pos=np.argmax(model.predict(padded_input_text))\n",
    "    \n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if index ==pos:\n",
    "            text=text+ \" \" +word\n",
    "            print(text)\n",
    "            time.sleep(2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94a6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c3128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c52fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
